{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f4d733f92d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "2024-01-11 01:24:05.719351: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 01:24:06.657677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"ClusterCast.settings\"\n",
    "import django\n",
    "django.setup()\n",
    "import sys\n",
    "sys.path.append(\"/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast\")\n",
    "from django.db.models.functions import Now\n",
    "from asgiref.sync import sync_to_async\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, RepeatVector, TimeDistributed, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "import ClusterPipeline.models.RNNModels as rnn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import ClusterPipeline.models.ClusterProcessing as cp\n",
    "import ClusterPipeline.models.RNNModels as rnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and Processing Dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Scaling Quant Min Max Features\n",
      "Quant Min Max Features Scaled\n",
      "Dataset Preprocessing Complete\n",
      "Creating Sequences\n",
      "Scaling Sequences\n",
      "Scaling Sequences Complete\n",
      "['SPY']\n",
      "Creating and Processing Dataset\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Scaling Quant Min Max Features\n",
      "Quant Min Max Features Scaled\n",
      "Dataset Preprocessing Complete\n",
      "Creating Sequences\n",
      "Scaling Sequences\n",
      "Scaling Sequences Complete\n",
      "['F']\n"
     ]
    }
   ],
   "source": [
    "@sync_to_async\n",
    "def get_all_objects(features,steps = None):\n",
    "    # Force the query to execute and load all results into memory\n",
    "    params = list(cp.StockClusterGroupParams.objects.all())\n",
    "    matching_groups = []\n",
    "    for param in params:\n",
    "        if steps is None:\n",
    "            if param.cluster_features == features:\n",
    "                group = cp.StockClusterGroup.objects.get(pk=param.pk)\n",
    "                matching_groups.append(group)\n",
    "                group.load_saved_group()\n",
    "\n",
    "        else: \n",
    "            if param.cluster_features == features and param.n_steps == steps:\n",
    "                group = cp.StockClusterGroup.objects.get(pk=param.pk)\n",
    "                matching_groups.append(group)\n",
    "                group.load_saved_group()\n",
    "                print(group.group_params.tickers)\n",
    "    \n",
    "    return matching_groups\n",
    "\n",
    "\n",
    "cluster_features = [\"close\", \"bb_low\", \"bb_high\"]\n",
    "steps = 20\n",
    "\n",
    "async def create_cluster_group_params(cluster_features, steps=20):\n",
    "\n",
    "    cluster_groups = await get_all_objects(features=cluster_features,steps=steps)\n",
    "    return cluster_groups\n",
    "\n",
    "# Run the async function\n",
    "\n",
    "matching_groups = await create_cluster_group_params(cluster_features, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync_to_async\n",
    "def get_all_clusters(groups):\n",
    "    clusters = []\n",
    "    features = []\n",
    "    for group in groups:\n",
    "        clusters += group.clusters\n",
    "\n",
    "    for cluster in clusters:\n",
    "        models = rnn.RNNModel.objects.filter(cluster=cluster)\n",
    "        for model in models: \n",
    "            if model:\n",
    "                features += (model.model_features)\n",
    "\n",
    "    features = list(set(features))\n",
    "    return clusters, features\n",
    "\n",
    "clusters, all_features = await get_all_clusters(matching_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster = clusters[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "features = random.sample(all_features, 50)\n",
    "\n",
    "feature_indices = [test_cluster.X_feature_dict[feature] for feature in features] \n",
    "test_cluster.X_train_filtered = test_cluster.X_train[:,:,feature_indices]\n",
    "test_cluster.X_test_filtered = test_cluster.X_test[:,:,feature_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Dropout, Multiply, Permute, RepeatVector, TimeDistributed, Flatten, Activation, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model_with_attention_and_teacher_forcing(input_shape, output_steps, latent_dim=6):\n",
    "    # Encoder\n",
    "    encoder_input = Input(shape=(None, input_shape))\n",
    "    encoder_lstm1 = LSTM(units=50, activation='tanh', return_sequences=True)(encoder_input)\n",
    "    encoder_lstm2 = LSTM(units=latent_dim, activation='tanh', return_sequences=True)(encoder_lstm1)\n",
    "    encoder_output = Dropout(0.2)(encoder_lstm2)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attention = Dense(1, activation='tanh')(encoder_output)\n",
    "    attention = Flatten()(attention)\n",
    "    attention_weights = Activation('softmax')(attention)\n",
    "    context = Multiply()([encoder_output, Permute([2, 1])(RepeatVector(latent_dim)(attention_weights))])\n",
    "    context_vector = Lambda(lambda x: x[:, -1, :])(context)  # Use the last context vector for initial state\n",
    "\n",
    "    # Adjust the dimensionality of the context vector\n",
    "    context_dense = Dense(75)(context_vector)  # Transform to match decoder LSTM units\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = Input(shape=(output_steps, 1))  # Adjust the shape as necessary\n",
    "    decoder_lstm = LSTM(units=75, activation='tanh', return_sequences=True)(decoder_input, initial_state=[context_dense, context_dense])\n",
    "    decoder_output = Dropout(0.2)(decoder_lstm)\n",
    "\n",
    "    # TimeDistributed layer for output\n",
    "    time_distributed_output = TimeDistributed(Dense(1))(decoder_output)\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=time_distributed_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, latent_dim=6):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(None, input_shape))\n",
    "\n",
    "    # masking_layer = Masking(mask_value=0.0, name='masking_layer')(input_layer)\n",
    "\n",
    "    # Encoder\n",
    "\n",
    "    encoder_lstm2 = LSTM(units=50, activation='tanh', return_sequences=True, name='encoder_lstm_2_restore')(input_layer)\n",
    "    encoder_dropout2 = Dropout(0.2, name='encoder_dropout_2_restore')(encoder_lstm2)\n",
    "\n",
    "    encoder_lstm3 = LSTM(units=100, activation='tanh', return_sequences=False, name='encoder_lstm_3_restore')(encoder_dropout2)\n",
    "    encoder_dropout3 = Dropout(0.2, name='encoder_dropout_3_restore')(encoder_lstm3)\n",
    "\n",
    "    # encoder_lstm4 = LSTM(units=50, activation='tanh', return_sequences=False, name='encoder_lstm_4_restore')(encoder_dropout3)\n",
    "    # encoder_dropout4 = Dropout(0.2, name='encoder_dropout_4_restore')(encoder_lstm4)\n",
    "\n",
    "    # Repeat Vector\n",
    "    repeat_vector = RepeatVector(latent_dim, name='repeat_vector')(encoder_dropout3)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_lstm1 = LSTM(units=50, activation='tanh', return_sequences=True, name='decoder_lstm_1_restore')(repeat_vector)\n",
    "    decoder_dropout1 = Dropout(0.2, name='decoder_dropout_1_restore')(decoder_lstm1)\n",
    "\n",
    "    decoder_lstm2 = LSTM(units=25, activation='tanh', return_sequences=True, name='decoder_lstm_2_restore')(decoder_dropout1)\n",
    "    decoder_dropout2 = Dropout(0.2, name='decoder_dropout_2_restore')(decoder_lstm2)\n",
    "\n",
    "    time_distributed_output = TimeDistributed(Dense(1), name='time_distributed_output')(decoder_dropout2)\n",
    "\n",
    "\n",
    "    # Create the model\n",
    "    model_lstm = Model(inputs=input_layer, outputs=time_distributed_output)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model_lstm.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    return model_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 20, 50)\n",
      "(188, 6)\n",
      "(43, 20, 50)\n",
      "(43, 6)\n",
      "(188, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = test_cluster.X_train_filtered\n",
    "y_train = test_cluster.y_train\n",
    "X_test = test_cluster.X_test_filtered\n",
    "y_test = test_cluster.y_test\n",
    "\n",
    "# Assuming y_train is your training data with shape (elements, output_steps)\n",
    "y_train_shifted = np.zeros_like(y_train)\n",
    "\n",
    "# Shift y_train by one time step\n",
    "y_train_shifted[:, 1:] = y_train[:, :-1]\n",
    "\n",
    "# Adding an extra dimension for features (assuming single feature per step)\n",
    "decoder_input_train = np.expand_dims(y_train_shifted, -1)\n",
    "\n",
    "start_token = 0\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(decoder_input_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 01:26:21.515402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.555631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.555783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.557354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.557551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.557703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.966455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.966635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.966750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-11 01:26:21.966832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 234 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-01-11 01:26:22.125352: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.126188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.126992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:22.265475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.266492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.267238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:22.402037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.402856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.403644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:22.538698: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.539692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.540406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:22.695471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.696301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.697090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:22.829792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:22.830895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:22.831606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:23.000339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:23.001173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:23.001878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "regular_model = create_model(X_train.shape[2], latent_dim=6)\n",
    "attention_model = create_model_with_attention_and_teacher_forcing(X_train.shape[2], 6,latent_dim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "def eval_model(X_test, y_test, model,cluster):\n",
    "\n",
    "    predicted_y = model.predict(X_test)\n",
    "    predicted_y = np.squeeze(predicted_y, axis=-1)\n",
    "\n",
    "    num_days = predicted_y.shape[1]  # Assuming this is the number of days\n",
    "    results = pd.DataFrame(predicted_y, columns=[f'predicted_{i+1}' for i in range(num_days)])\n",
    "\n",
    "    for i in range(num_days):\n",
    "        results[f'real_{i+1}'] = y_test[:, i]\n",
    "\n",
    "    # Generate output string with accuracies\n",
    "    output_string = f\"Cluster Number: {cluster.label}\\n\"\n",
    "    for i in range(num_days):\n",
    "        same_day = ((results[f'predicted_{i+1}'] > 0) & (results[f'real_{i+1}'] > 0)) | \\\n",
    "                ((results[f'predicted_{i+1}'] < 0) & (results[f'real_{i+1}'] < 0))\n",
    "        accuracy = round(same_day.mean() * 100,2)\n",
    "\n",
    "        output_string += (\n",
    "            f\"Accuracy{i+1}D {accuracy}% \"\n",
    "            f\"PredictedRet: {results[f'predicted_{i+1}'].mean()} \"\n",
    "            f\"ActRet: {results[f'real_{i+1}'].mean()}\\n\"\n",
    "        )\n",
    "    \n",
    "    output_string += f\"Train set length: {len(X_train)} Test set length: {len(y_test)}\\n\"\n",
    "\n",
    "    return output_string, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "regular_model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Set up early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True)\n",
    "\n",
    "# Fine-tune the model using your smaller dataset\n",
    "# Assume you have 'small_train_data', 'small_train_labels', 'small_val_data', and 'small_val_labels'\n",
    "history = regular_model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=250,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model performance\n",
    "val_loss = regular_model.evaluate(X_test, y_test)\n",
    "regularAccuracy,regularResults = eval_model(X_test, y_test, regular_model,test_cluster)\n",
    "clear_session()\n",
    "del regular_model\n",
    "print(f'Validation loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 01:26:27.212320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:27.213461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:27.214298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:27.342228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:27.343098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:27.343910: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:27.487816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:27.488941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:27.489733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:28.178616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:28.179710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:28.180483: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:28.308786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:28.309667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:28.310490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:28.454629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-11 01:26:28.455689: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-11 01:26:28.456478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-11 01:26:29.731509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8904\n",
      "2024-01-11 01:26:29.822241: E tensorflow/compiler/xla/stream_executor/dnn.cc:893] CUDNN_STATUS_ALLOC_FAILED\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(2305): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\n",
      "2024-01-11 01:26:29.822262: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1970 : INTERNAL: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 75, 1, 6, 32, 75] \n",
      "2024-01-11 01:26:29.822277: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 75, 1, 6, 32, 75] \n",
      "\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n",
      "2024-01-11 01:26:29.822305: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: {{function_node __inference___backward_gpu_lstm_with_fallback_8233_8409_specialized_for_Adam_gradients_PartitionedCall_at___inference_train_function_10383}} {{function_node __inference___backward_gpu_lstm_with_fallback_8233_8409_specialized_for_Adam_gradients_PartitionedCall_at___inference_train_function_10383}} Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 75, 1, 6, 32, 75] \n",
      "\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n",
      "\t [[Adam/gradients/PartitionedCall]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 75, 1, 6, 32, 75] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_10383]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m attention_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m attention_model\u001b[39m.\u001b[39;49mfit([X_train, decoder_input_train], y_train, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Evaluate the model performance\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacet116-lnx-13.bucknell.edu/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast/teacherforcingExperiment.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m val_loss \u001b[39m=\u001b[39m attention_model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/remote/apps/anaconda/2023.03-acet116/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 75, 1, 6, 32, 75] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_10383]"
     ]
    }
   ],
   "source": [
    "# optimizer = Adam(learning_rate=0.0001)\n",
    "# attention_model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Set up early stopping to avoid overfitting\n",
    "# Compile the model\n",
    "attention_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = attention_model.fit([X_train, decoder_input_train], y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2)\n",
    "\n",
    "# Evaluate the model performance\n",
    "val_loss = attention_model.evaluate(X_test, y_test)\n",
    "print(f'Validation loss: {val_loss}')\n",
    "attentionAccuracy,attentionResults = eval_model(X_test, y_test, attention_model,test_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def visualize_future_distribution(results):\n",
    "    '''\n",
    "    Create stacked box and whisker plots for the predicted and real values\n",
    "    '''\n",
    "\n",
    "    fig = go.Figure()\n",
    "    print(results.shape)\n",
    "\n",
    "    for i in range(6):\n",
    "\n",
    "        fig.add_trace(go.Box(y=results[f'predicted_{i+1}'], name=f'Predicted {i}')) \n",
    "        fig.add_trace(go.Box(y=results[f'real_{i+1}'], name=f'Real {i}'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Future Performance of Cluster',\n",
    "        xaxis_title='Steps in future',\n",
    "        yaxis_title='Cumulative Percent Change'\n",
    "    ) \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "bench_fig = visualize_future_distribution(regularResults)\n",
    "tuned_fig = visualize_future_distribution(attentionResults)\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "for trace in bench_fig.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in tuned_fig.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regularAccuracy)\n",
    "print(attentionAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
