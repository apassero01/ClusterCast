{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DJANGO_SETTINGS_MODULE'] = 'ClusterCast.settings'\n",
    "import test_utils\n",
    "import django\n",
    "django.setup()\n",
    "import sys\n",
    "sys.path.append(\"/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast\")\n",
    "from asgiref.sync import sync_to_async\n",
    "from importlib import reload\n",
    "import ClusterPipeline.models.ClusterProcessing as cp\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(test_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = [40]\n",
    "groups = await test_utils.extract_cluster_groups(group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = await test_utils.get_all_clusters(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_interest_id = 444\n",
    "cluster_of_interest = [cluster for cluster in clusters if cluster.id == cluster_of_interest_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = groups[0].group_params.training_features\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_group = groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_group = await test_utils.recreate_group(cur_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train, X_test, y_test = cur_group.get_3d_array() \n",
    "X_train = X_train.copy()[::-1]\n",
    "y_train = y_train.copy()[::-1]\n",
    "X_test = X_test.copy()[::-1]\n",
    "y_test = y_test.copy()[::-1]\n",
    "cluster_features = cur_group.group_params.cluster_features\n",
    "X_feature_dict = cur_group.group_params.X_feature_dict\n",
    "y_feature_dict = cur_group.group_params.y_feature_dict\n",
    "training_dict = {}\n",
    "training_dict['0'] = (0,(X_train, y_train, X_test, y_test))\n",
    "print(training_dict['0'][1][0].shape)\n",
    "print(training_dict['0'][1][1].shape)\n",
    "print(training_dict['0'][1][2].shape)\n",
    "print(training_dict['0'][1][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_feature_dict))\n",
    "print(len(cur_group.group_params.X_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_clusters = test_utils.cluster_a_group(cur_group,training_dict['0'][1],4)\n",
    "next_label = 2\n",
    "training_dict['1'] = next_clusters[next_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(next_clusters)): \n",
    "    print(next_clusters[i][0].shape)\n",
    "    plot = test_utils.visualize_cluster_centroid(next_clusters[i][0],cluster_features)\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_clusters = test_utils.cluster_a_group(cur_group,training_dict['1'][1],2)\n",
    "for i in range(len(next_clusters)): \n",
    "    print(next_clusters[i][0].shape)\n",
    "    plot = test_utils.visualize_cluster_centroid(next_clusters[i][0],cluster_features)\n",
    "    plot.show()\n",
    "next_label = 0\n",
    "training_dict['2'] = next_clusters[next_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_clusters = test_utils.cluster_a_group(cur_group,training_dict['2'][1],3)\n",
    "for i in range(len(next_clusters)): \n",
    "    print(next_clusters[i][0].shape)\n",
    "    plot = test_utils.visualize_cluster_centroid(next_clusters[i][0],cluster_features)\n",
    "    plot.show()\n",
    "next_label = 1\n",
    "training_dict['3'] = (next_clusters[next_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "target_features = [] \n",
    "# target_features += ['pctChgclose{}_target'.format(i) for i in range(-14, 0) ]\n",
    "# target_features += ['pctChgclose-0_target']\n",
    "target_features += ['pctChgclose+{}_target'.format(i) for i in range(1, 16) ]\n",
    "training_features = random.sample(features, 20)\n",
    "training_features += ['pctChgclose']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(test_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_features)\n",
    "print(len(target_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid =  training_dict['0'][0]\n",
    "X_train, y_train, X_test, y_test = training_dict['0'][1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_index = X_feature_dict['pctChgclose']\n",
    "X_train[:,:,bb_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_group.run_clustering()\n",
    "# all_centroids = cur_group.cluster_centers\n",
    "\n",
    "# closted_centroid_label = test_utils.find_closest_centroid(centroid,all_centroids)\n",
    "# print(closted_centroid_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cur_group.cluster_centers.shape)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(closted_centroid_label)\n",
    "# test_utils.visualize_cluster_centroid(centroid,cluster_features).show()\n",
    "# test_utils.visualize_cluster_centroid(all_centroids[closted_centroid_label],cluster_features).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cur_group.clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_filtered = test_utils.filter_by_features(X_train, training_features, X_feature_dict)\n",
    "X_test_filtered = test_utils.filter_by_features(X_test, training_features, X_feature_dict)\n",
    "y_train_filtered = test_utils.filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = test_utils.filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "print(X_train_filtered.shape)\n",
    "print(y_train_filtered.shape)\n",
    "print(X_test_filtered.shape)\n",
    "print(y_test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_filtered[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_attention_model, test_attention_model = test_utils.create_attention_model(input_steps=X_train.shape[1],output_steps=len(target_features),features=len(training_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights = test_utils.save_decoder_initial_weights(training_attention_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainined_attention_model = test_utils.train_model(training_attention_model, (X_train, y_train, X_test, y_test), training_features, \n",
    "                                                   target_features, X_feature_dict, y_feature_dict,\n",
    "                                                   epochs = 100, batch_size = 128, lr = 0.001, early_stopping_patience = 15,\n",
    "                                                   loss = 'mse', shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 15\n",
    "attention_model_accuracy, attention_results, predicted_y, attention_weights = test_utils.eval_model(X_test_filtered, y_test_filtered, trainined_attention_model,num_days, test_model = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in trainined_attention_model.layers:\n",
    "    if 'freeze' in layer.name:\n",
    "        layer.trainable = False\n",
    "        continue\n",
    "    if 'input' in layer.name:\n",
    "        continue\n",
    "    layer.set_weights(decoder_weights[layer.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(test_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attention_model_accuracy)\n",
    "test_utils.visualize_future_distribution(attention_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid =  training_dict['2'][0]\n",
    "X_train_smaller, y_train_smaller, X_test_smaller, y_test_smaller= training_dict['2'][1]\n",
    "# X_train_larger = np.concatenate((X_train, X_train_larger), axis=0)\n",
    "# y_train_larger = np.concatenate((y_train, y_train_larger), axis=0)\n",
    "# X_test_larger = np.concatenate((X_test, X_test_larger), axis=0)\n",
    "# y_test_larger = np.concatenate((y_test, y_test_larger), axis=0)\n",
    "\n",
    "# X_train_larger = np.concatenate((X_train, X_train_larger), axis=0)\n",
    "# y_train_larger = np.concatenate((y_train, y_train_larger), axis=0)\n",
    "# X_test_larger = np.concatenate((X_test, X_test_larger), axis=0)\n",
    "# y_test_larger = np.concatenate((y_test, y_test_larger), axis=0)\n",
    "\n",
    "X_train_smaller_filtered = test_utils.filter_by_features(X_train_smaller, training_features, X_feature_dict)\n",
    "X_test_smaller_filtered = test_utils.filter_by_features(X_test_smaller, training_features, X_feature_dict)\n",
    "y_train_smaller_filtered = test_utils.filter_y_by_features(y_train_smaller, target_features, y_feature_dict)\n",
    "y_test_smaller_filtered = test_utils.filter_y_by_features(y_test_smaller, target_features, y_feature_dict)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train_smaller_filtered.shape)\n",
    "print(y_train_smaller_filtered.shape)\n",
    "print(X_test_smaller_filtered.shape)\n",
    "print(y_test_smaller_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_train_model = test_utils.train_model(trainined_attention_model, (X_train_smaller, y_train_smaller, X_test_smaller, y_test_smaller), training_features, \n",
    "                                                   target_features, X_feature_dict, y_feature_dict,\n",
    "                                                   epochs = 150, batch_size = 8, lr = 0.0001, early_stopping_patience = 30,\n",
    "                                                   loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data_set_accuracy, large_data_set_results, predicted_y, attention_weights = test_utils.eval_model(X_test_smaller_filtered, y_test_smaller_filtered, test_attention_model, num_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = test_utils.create_attention_model(input_steps=X_train.shape[1],output_steps=len(target_features),features=len(training_features))\n",
    "benchark_model = test_utils.train_model(benchmark_model, (X_train_smaller, y_train_smaller, X_test_smaller, y_test_smaller), training_features,\n",
    "                                        target_features, X_feature_dict, y_feature_dict,\n",
    "                                        epochs = 250, batch_size = 32, lr = 0.001, early_stopping_patience = 30,\n",
    "                                        loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchark_model = test_utils.train_model(benchmark_model, (X_train_smaller, y_train_smaller, X_test_smaller, y_test_smaller), training_features,\n",
    "#                                         target_features, X_feature_dict, y_feature_dict,\n",
    "#                                         epochs = 250, batch_size = 16, lr = 0.0001, early_stopping_patience = 30,\n",
    "#                                         loss = test_utils.custom_profit_loss_percent_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_model_accuracy, bench_results = test_utils.eval_model(X_test_smaller_filtered, y_test_smaller_filtered, benchmark_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINE TUNED MODEL\")\n",
    "print(large_data_set_accuracy)\n",
    "test_utils.visualize_future_distribution(large_data_set_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BENCHMARK MODEL\")\n",
    "print(bench_model_accuracy)\n",
    "test_utils.visualize_future_distribution(bench_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
