{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"] = \"ClusterCast.settings\"\n",
    "import django\n",
    "django.setup()\n",
    "import sys\n",
    "sys.path.append(\"/home/ajp031/StockDeepLearning/ClusterCast/ClusterCast\")\n",
    "from django.db.models.functions import Now\n",
    "from asgiref.sync import sync_to_async\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, RepeatVector, TimeDistributed, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "import ClusterPipeline.models.RNNModels as rnn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import tensorflow as tf\n",
    "import ClusterPipeline.models.ClusterProcessing as cp\n",
    "import ClusterPipeline.models.RNNModels as rnn \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync_to_async\n",
    "def get_all_objects(features,steps = None):\n",
    "    # Force the query to execute and load all results into memory\n",
    "    params = list(cp.StockClusterGroupParams.objects.all())\n",
    "    matching_groups = []\n",
    "    for param in params:\n",
    "        continue\n",
    "        if steps is None:\n",
    "            if param.cluster_features == features:\n",
    "                group = cp.StockClusterGroup.objects.get(pk=param.pk)\n",
    "                matching_groups.append(group)\n",
    "                group.load_saved_group()\n",
    "\n",
    "        else: \n",
    "            if param.cluster_features == features and param.n_steps == steps:\n",
    "                group = cp.StockClusterGroup.objects.get(pk=param.pk)\n",
    "                matching_groups.append(group)\n",
    "                group.load_saved_group()\n",
    "                print(group.group_params.tickers)\n",
    "\n",
    "    group = cp.StockClusterGroup.objects.get(pk=367)\n",
    "    group.load_saved_group()\n",
    "    \n",
    "    return matching_groups,group\n",
    "\n",
    "\n",
    "cluster_features = [\"close\", \"bb_low\", \"bb_high\"]\n",
    "steps = 20\n",
    "\n",
    "async def create_cluster_group_params(cluster_features, steps=20):\n",
    "\n",
    "    cluster_groups,group = await get_all_objects(features=cluster_features,steps=steps)\n",
    "    return cluster_groups,group\n",
    "\n",
    "# Run the async function\n",
    "\n",
    "matching_groups,group = await create_cluster_group_params(cluster_features, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync_to_async\n",
    "def get_all_clusters(groups):\n",
    "    clusters = []\n",
    "    features = []\n",
    "    for group in groups:\n",
    "        clusters += group.clusters\n",
    "\n",
    "    for cluster in clusters:\n",
    "        models = rnn.RNNModel.objects.filter(cluster=cluster)\n",
    "        for model in models: \n",
    "            if model:\n",
    "                features += (model.model_features)\n",
    "\n",
    "    features = list(set(features))\n",
    "    return clusters, features\n",
    "\n",
    "clusters, all_features = await get_all_clusters(matching_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group = group\n",
    "print(test_group.id)\n",
    "cluster_features = test_group.group_params.cluster_features\n",
    "feature_dict = test_group.group_params.X_feature_dict\n",
    "y_feature_dict = test_group.group_params.y_feature_dict\n",
    "print(len(test_group.clusters))\n",
    "training_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_top, y_train_top, X_test_top, y_test_top = test_group.get_3d_array()\n",
    "y_train_top_reversed = y_train_top[:, ::-1]\n",
    "y_test_top_reversed = y_test_top[:, ::-1]\n",
    "training_dict[\"first\"] = (X_train_top, y_train_top, X_test_top, y_test_top)\n",
    "print(X_train_top.shape)\n",
    "print(y_train_top.shape)\n",
    "print(X_test_top.shape)\n",
    "print(y_test_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_cluster_centroid(centroid, cluster_features):\n",
    "\n",
    "    # Extract the number of features\n",
    "    num_features = centroid.shape[1]\n",
    "\n",
    "    # Set up the time steps\n",
    "    time_steps = range(centroid.shape[0])\n",
    "\n",
    "    # Plot the centroid for each feature\n",
    "    for i in range(num_features):\n",
    "        plt.scatter(time_steps, centroid[:,i], label=f'Feature {cluster_features[i]}')\n",
    "        plt.plot(time_steps, centroid[:,i], 'kx-')  # 'kx-' for black crosses with lines\n",
    "\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Feature Values')\n",
    "    plt.title('Centroid Visualization Over Time Steps')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_alg = TimeSeriesKMeans(n_clusters=2, metric=\"euclidean\", max_iter=5, random_state=0)\n",
    "X_train_top, y_train_top, X_test_top, y_test_top = training_dict[\"first\"]\n",
    "X_train_cluster = test_group.filter_by_features(X_train_top, cluster_features, feature_dict)\n",
    "X_test_cluster = test_group.filter_by_features(X_test_top, cluster_features, feature_dict)\n",
    "\n",
    "print(X_train_cluster.shape)\n",
    "print(X_test_cluster.shape)\n",
    "\n",
    "first_alg.fit(X_train_cluster)\n",
    "\n",
    "print(first_alg.cluster_centers_.shape)\n",
    "\n",
    "labels = first_alg.labels_\n",
    "target_label = 1\n",
    "\n",
    "\n",
    "visualize_cluster_centroid(first_alg.cluster_centers_[target_label], cluster_features)\n",
    "visualize_cluster_centroid(first_alg.cluster_centers_[0], cluster_features)\n",
    "\n",
    "\n",
    "X_train_top = X_train_top[labels == target_label]\n",
    "\n",
    "y_train_top = y_train_top[labels == target_label]\n",
    "\n",
    "test_labels = first_alg.predict(X_test_cluster)\n",
    "X_test_top = X_test_top[test_labels == target_label]\n",
    "y_test_top = y_test_top[test_labels == target_label]\n",
    "\n",
    "training_dict[\"second\"] = (deepcopy(X_train_top), deepcopy(y_train_top), deepcopy(X_test_top), deepcopy(y_test_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_top.shape)\n",
    "print(y_train_top.shape)\n",
    "print(X_test_top.shape)\n",
    "print(y_test_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_alg = TimeSeriesKMeans(n_clusters=2, metric=\"euclidean\", max_iter=5, random_state=0)\n",
    "X_train_top, y_train_top, X_test_top, y_test_top = training_dict[\"second\"]\n",
    "X_train_cluster = test_group.filter_by_features(X_train_top, cluster_features, feature_dict)\n",
    "X_test_cluster = test_group.filter_by_features(X_test_top, cluster_features, feature_dict)\n",
    "\n",
    "print(X_train_cluster.shape)\n",
    "print(X_test_cluster.shape)\n",
    "\n",
    "second_alg.fit(X_train_cluster)\n",
    "\n",
    "labels = second_alg.labels_\n",
    "target_label = 1\n",
    "\n",
    "visualize_cluster_centroid(second_alg.cluster_centers_[target_label], cluster_features)\n",
    "visualize_cluster_centroid(second_alg.cluster_centers_[0], cluster_features)\n",
    "\n",
    "print(set(labels))\n",
    "X_train_top = X_train_top[labels == target_label]\n",
    "\n",
    "y_train_top = y_train_top[labels == target_label]\n",
    "\n",
    "test_labels = second_alg.predict(X_test_cluster)\n",
    "X_test_top = X_test_top[test_labels == target_label]\n",
    "y_test_top = y_test_top[test_labels == target_label]\n",
    "\n",
    "training_dict[\"third\"] = (deepcopy(X_train_top), deepcopy(y_train_top), deepcopy(X_test_top), deepcopy(y_test_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_top.shape)\n",
    "print(y_train_top.shape)\n",
    "print(X_test_top.shape)\n",
    "print(y_test_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_alg = TimeSeriesKMeans(n_clusters=3, metric=\"euclidean\", max_iter=5, random_state=0)\n",
    "X_train_top, y_train_top, X_test_top, y_test_top = training_dict[\"third\"]\n",
    "X_train_cluster = test_group.filter_by_features(X_train_top, cluster_features, feature_dict)\n",
    "X_test_cluster = test_group.filter_by_features(X_test_top, cluster_features, feature_dict)\n",
    "\n",
    "print(X_train_cluster.shape)\n",
    "print(X_test_cluster.shape)\n",
    "\n",
    "third_alg.fit(X_train_cluster)\n",
    "\n",
    "labels = third_alg.labels_\n",
    "target_label = 0\n",
    "\n",
    "for i in range(3):\n",
    "    visualize_cluster_centroid(third_alg.cluster_centers_[i], cluster_features)\n",
    "\n",
    "\n",
    "print(set(labels))\n",
    "X_train_top = X_train_top[labels == target_label]\n",
    "\n",
    "y_train_top = y_train_top[labels == target_label]\n",
    "\n",
    "test_labels = third_alg.predict(X_test_cluster)\n",
    "X_test_top = X_test_top[test_labels == target_label]\n",
    "y_test_top = y_test_top[test_labels == target_label]\n",
    "\n",
    "training_dict[\"last\"] = (deepcopy(X_train_top), deepcopy(y_train_top), deepcopy(X_test_top), deepcopy(y_test_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_top.shape)\n",
    "print(y_train_top.shape)\n",
    "print(X_test_top.shape)\n",
    "print(y_test_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dropout, TimeDistributed, Dense, Concatenate, Permute, Reshape, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Activation, Flatten\n",
    "from tensorflow.keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def create_model(input_shape, latent_dim=6):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(None, input_shape))\n",
    "\n",
    "    # masking_layer = Masking(mask_value=0.0, name='masking_layer')(input_layer)\n",
    "\n",
    "    # Encoder\n",
    "\n",
    "    encoder_lstm2 = LSTM(units=100, activation='tanh', return_sequences=True, name='encoder_lstm_2_restore')(input_layer)\n",
    "    encoder_dropout2 = Dropout(0.2, name='encoder_dropout_2_restore')(encoder_lstm2)\n",
    "\n",
    "    encoder_lstm3 = LSTM(units=50, activation='tanh', return_sequences=False, name='encoder_lstm_3_restore')(encoder_dropout2)\n",
    "    encoder_dropout3 = Dropout(0.2, name='encoder_dropout_3_restore')(encoder_lstm3)\n",
    "\n",
    "    # encoder_lstm4 = LSTM(units=50, activation='tanh', return_sequences=False, name='encoder_lstm_4_restore')(encoder_dropout3)\n",
    "    # encoder_dropout4 = Dropout(0.2, name='encoder_dropout_4_restore')(encoder_lstm4)\n",
    "\n",
    "    # Repeat Vector\n",
    "    repeat_vector = RepeatVector(latent_dim, name='repeat_vector')(encoder_dropout3)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_lstm1 = LSTM(units=100, activation='tanh', return_sequences=True, name='decoder_lstm_1_restore')(repeat_vector)\n",
    "    decoder_dropout1 = Dropout(0.2, name='decoder_dropout_1_restore')(decoder_lstm1)\n",
    "\n",
    "    decoder_lstm2 = LSTM(units=50, activation='tanh', return_sequences=True, name='decoder_lstm_2_restore')(decoder_dropout1)\n",
    "    decoder_dropout2 = Dropout(0.2, name='decoder_dropout_2_restore')(decoder_lstm2)\n",
    "\n",
    "    time_distributed_output = TimeDistributed(Dense(1), name='time_distributed_output')(decoder_dropout2)\n",
    "\n",
    "\n",
    "    # Create the model\n",
    "    model_lstm = Model(inputs=input_layer, outputs=time_distributed_output)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model_lstm.compile(optimizer=optimizer, loss=\"mae\")\n",
    "\n",
    "    return model_lstm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelAE(input_shape, latent_dim=6):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(None, input_shape),name = 'input_layer')\n",
    "\n",
    "    # masking_layer = Masking(mask_value=0.0, name='masking_layer')(input_layer)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_lstm1 = LSTM(units=300, activation='tanh', return_state=True,return_sequences=True,\n",
    "                     name='encoder_lstm_1_freeze', kernel_regularizer=L2(.001), recurrent_regularizer=L2(.001))\n",
    "    encoder_outputs1 = encoder_lstm1(input_layer)\n",
    "    encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "    encoder_lstm2 = LSTM(units=200, activation='tanh', return_state=True,return_sequences=True, name = 'encoder_lstm_2_freeze',\n",
    "                         )\n",
    "    encoder_outputs2 = encoder_lstm2(encoder_outputs1[0])\n",
    "    encoder_states2 = encoder_outputs2[1:]\n",
    "\n",
    "    encoder_lstm3 = LSTM(units=150, activation='tanh', return_state=True,return_sequences=True, name='encoder_lstm_3_freeze')\n",
    "    encoder_outputs3 = encoder_lstm3(encoder_outputs2[0])\n",
    "    encoder_states3 = encoder_outputs3[1:]\n",
    "\n",
    "    encoder_lstm4 = LSTM(units=100, activation='tanh', return_state=True,return_sequences=True, name='encoder_lstm_4_restore')\n",
    "    encoder_outputs4 = encoder_lstm4(encoder_outputs3[0])\n",
    "    encoder_states4 = encoder_outputs4[1:]\n",
    "\n",
    "\n",
    "    # attention = Dense(1, activation='tanh')(encoder_lstm4)\n",
    "    # attention = Flatten()(attention)\n",
    "    # attention_weights = Activation('softmax')(attention)\n",
    "    # context = Multiply()([encoder_lstm4, Permute([2, 1])(RepeatVector(6)(attention_weights))])\n",
    "\n",
    "    decoder_inputs = RepeatVector(21, name='repeat_vector')(encoder_states4[0])\n",
    "    \n",
    "\n",
    "    # Decoder\n",
    "    decoder_lstm1 = LSTM(units=300, activation='tanh', return_sequences=True, name='decoder_lstm_1_freeze',\n",
    "    \n",
    "                        )(decoder_inputs, initial_state=encoder_states1)\n",
    "    decoder_lstm2 = LSTM(units=200, activation='tanh', return_sequences=True, name='decoder_lstm_2_freeze',\n",
    "                        )(decoder_lstm1, initial_state=encoder_states2)\n",
    "    decoder_lstm3 = LSTM(units=150, activation='tanh', return_sequences=True, name='decoder_lstm_3_freeze',\n",
    "                         )(decoder_lstm2, initial_state=encoder_states3)\n",
    "    decoder_lstm4 = LSTM(units=100, activation='tanh', return_sequences=True, name='decoder_lstm_4_restore',\n",
    "                         )(decoder_lstm3, initial_state=encoder_states4)\n",
    "\n",
    "    # decoder_lstm3 = LSTM(units=5, activation='tanh', return_sequences=True, name='decoder_lstm_3_restore',\n",
    "    #                      )(decoder_dropout2)\n",
    "    # decoder_dropout3 = Dropout(0.2, name='decoder_dropout_3_restore')(decoder_lstm3)\n",
    "\n",
    "    \n",
    "\n",
    "    time_distributed_output = TimeDistributed(Dense(1), name='time_distributed_output')(decoder_lstm4)\n",
    "\n",
    "    # final_output = time_distributed_output[:, -6:, :]\n",
    "\n",
    "    # Create the model\n",
    "    model_lstm = Model(inputs=input_layer, outputs=time_distributed_output)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model_lstm.compile(optimizer=optimizer, loss=\"mae\")\n",
    "\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Attention Layer\n",
    "\n",
    "def create_model_with_attention2(input_shape, latent_dim=6):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(None, input_shape),name = 'input_layer')\n",
    "\n",
    "    # Encoder\n",
    "\n",
    "    encoder_lstm1 = LSTM(units=40, activation='tanh', return_sequences=True, name='encoder_lstm_1_freeze',kernel_regularizer=L2(.0001), recurrent_regularizer=L2(.0001))(input_layer)\n",
    "    encoder_dropout1 = Dropout(0.2, name='encoder_dropout_1_freeze')(encoder_lstm1)\n",
    "\n",
    "    encoder_lstm2 = LSTM(units=50, activation='tanh', return_sequences=True, name='encoder_lstm_2_freeze')(encoder_dropout1)\n",
    "    encoder_dropout2 = Dropout(0.2, name='encoder_dropout_2_freeze')(encoder_lstm2)\n",
    "\n",
    "    encoder_lstm3 = LSTM(units=25, activation='tanh', return_sequences=True, name='encoder_lstm_3_freeze')(encoder_dropout2)\n",
    "    encoder_dropout3 = Dropout(0.2, name='encoder_dropout_3_freeze')(encoder_lstm3)\n",
    "\n",
    "    output_lstm = LSTM(units=6, activation='tanh', return_sequences=True, name='outputLSTM_freeze')(encoder_dropout3)\n",
    "    encoder_output = Dropout(0.2, name='encoder_output_freeze')(output_lstm)\n",
    "\n",
    "    # encoder_lstm4 = LSTM(units=50, activation='tanh', return_sequences=True, name='encoder_lstm_4_restore')(encoder_dropout3)\n",
    "    # encoder_dropout4 = Dropout(0.2, name='encoder_dropout_4_restore')(encoder_lstm4)\n",
    "\n",
    "    # Attention Layer\n",
    "    # attention = AttentionLayer(name='attention_layer')(encoder_dropout4)\n",
    "     # Attention Mechanism\n",
    "    attention = Dense(1, activation='tanh')(encoder_output)\n",
    "    attention = Flatten()(attention)\n",
    "    attention_weights = Activation('softmax')(attention)\n",
    "    context = Multiply()([encoder_output, Permute([2, 1])(RepeatVector(6)(attention_weights))])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_lstm1 = LSTM(units=50, activation='tanh', return_sequences=True, name='decoder_lstm_1')(context)\n",
    "    decoder_dropout1 = Dropout(0.2, name='decoder_dropout_1')(decoder_lstm1)\n",
    "\n",
    "    decoder_lstm2 = LSTM(units=25, activation='tanh', return_sequences=True, name='decoder_lstm_2')(decoder_dropout1)\n",
    "    decoder_dropout2 = Dropout(0.2, name='decoder_dropout_2')(decoder_lstm2)\n",
    "\n",
    "    # decoder_lstm3 = LSTM(units=5, activation='tanh', return_sequences=True, name='decoder_lstm_3_restore')(decoder_dropout2)\n",
    "    # decoder_dropout3 = Dropout(0.2, name='decoder_dropout_3_restore')(decoder_lstm3)\n",
    "\n",
    "    time_distributed_output = TimeDistributed(Dense(1), name='time_distributed_output')(decoder_dropout2)\n",
    "\n",
    "    # final_output = time_distributed_output[:, -6:, :]\n",
    "\n",
    "    # Create the model\n",
    "    model_lstm = Model(inputs=input_layer, outputs=final_output)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model_lstm.compile(optimizer=optimizer, loss=\"mae\")\n",
    "\n",
    "    return model_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_mechanism(encoder_outputs, decoder_state):\n",
    "    # Assuming encoder_outputs is [batch_size, input_steps, features]\n",
    "    # and decoder_state is [batch_size, features]\n",
    "    score = Dense(encoder_outputs.shape[2])(decoder_state)  # Project decoder state\n",
    "    score = tf.expand_dims(score, 1)  # Expand dims to add input_steps axis\n",
    "    score = score + encoder_outputs  # Add to encoder outputs\n",
    "    attention_weights = Activation('softmax')(score)  # Compute attention weights\n",
    "    context_vector = tf.reduce_sum(attention_weights * encoder_outputs, axis=1)\n",
    "    return context_vector\n",
    "\n",
    "def create_autoencoder(input_steps, output_steps, features):\n",
    "    # Encoder\n",
    "\n",
    "    encoder_inputs = Input(shape=(input_steps, features))\n",
    "\n",
    "    encoder_lstm1 = LSTM(200, return_sequences=True, kernel_regularizer=L2(.001), recurrent_regularizer=L2(.001))\n",
    "    encoder_output1 = encoder_lstm1(encoder_inputs)\n",
    "\n",
    "    encoder_lstm_final = LSTM(100, return_state=True, return_sequences=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm_final(encoder_output1)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_initial_input = RepeatVector(output_steps)(state_h)  # Prepare decoder inputs\n",
    "\n",
    "\n",
    "    decoder_lstm = LSTM(100, return_sequences=True)\n",
    "    decoder_output1 = decoder_lstm(decoder_initial_input, initial_state=[state_h, state_c])\n",
    "\n",
    "    # Manually apply attention mechanism for each timestep\n",
    "    context_vectors_list1 = []\n",
    "    for t in range(output_steps):\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        context_vector_t1 = attention_mechanism(encoder_outputs, decoder_output1[:, t, :])\n",
    "        context_vectors_list1.append(context_vector_t1)\n",
    "\n",
    "    # Concatenate the list of context vectors\n",
    "    context_vectors = tf.stack(context_vectors_list1, axis=1)\n",
    "\n",
    "    # Concatenate context vectors with decoder outputs\n",
    "    decoder_combined_context1 = Concatenate(axis=-1)([context_vectors, decoder_output1])\n",
    "\n",
    "    decoder_lstm2 = LSTM(50, return_sequences=True)\n",
    "    decoder_output2 = decoder_lstm2(decoder_combined_context1)\n",
    "\n",
    "    # Manually apply attention mechanism for each timestep\n",
    "    context_vectors_list2 = []\n",
    "    for t in range(output_steps):\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        context_vector_t2 = attention_mechanism(encoder_outputs, decoder_output2[:, t, :])\n",
    "        context_vectors_list2.append(context_vector_t2)\n",
    "    \n",
    "    # Concatenate the list of context vectors\n",
    "    context_vectors2 = tf.stack(context_vectors_list2, axis=1)\n",
    "    decoder_combined_context2 = Concatenate(axis=-1)([context_vectors2, decoder_output2])\n",
    "\n",
    "\n",
    "\n",
    "    # Output layer for reconstruction\n",
    "    output = TimeDistributed(Dense(1))(decoder_combined_context2)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Model(inputs=encoder_inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')  # Use appropriate loss\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss_function(y_true, y_pred, past_steps, future_weight):\n",
    "    \"\"\"\n",
    "    Custom loss function that assigns different weights to the errors in predicting \n",
    "    past and future values in a sequence.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (tensor): The true values.\n",
    "    y_pred (tensor): The predicted values from the model.\n",
    "    past_steps (int): The number of steps in the sequence corresponding to past values.\n",
    "    future_steps (int): The number of steps in the sequence corresponding to future values.\n",
    "    future_weight (float): The weight to assign to the errors in the future values.\n",
    "\n",
    "    Returns:\n",
    "    tensor: The computed weighted loss.\n",
    "    \"\"\"\n",
    "    # Split the true and predicted values into past and future parts\n",
    "    y_true_past, y_true_future = y_true[:, :past_steps], y_true[:, past_steps:]\n",
    "    y_pred_past, y_pred_future = y_pred[:, :past_steps], y_pred[:, past_steps:]\n",
    "\n",
    "    # Calculate mean absolute error for past and future parts\n",
    "    past_loss = tf.keras.losses.mean_squared_error(y_true_past, y_pred_past)\n",
    "    future_loss = tf.keras.losses.mean_squared_error(y_true_future, y_pred_future)\n",
    "\n",
    "    if future_weight == 1:\n",
    "        # If future_weight is 1, calculate normal MAE across the entire sequence\n",
    "        total_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        # Weight the future loss and combine it with the past loss\n",
    "        weighted_future_loss = future_loss * future_weight\n",
    "        total_loss = tf.reduce_mean(past_loss + weighted_future_loss)\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_features(sequence, features,X_feature_dict):\n",
    "    sequence = deepcopy(sequence)\n",
    "    feature_indices = [X_feature_dict[feature] for feature in features]\n",
    "    return sequence[:,:,feature_indices]\n",
    "\n",
    "def filter_y_by_features(sequence, features,y_feature_dict):\n",
    "    sequence = deepcopy(sequence)\n",
    "    feature_indices = [y_feature_dict[feature] for feature in features]\n",
    "    print(feature_indices)\n",
    "    return sequence[:,feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# features = random.sample(all_features, 30)\n",
    "features = [\n",
    "    \"sumpctChg+pctChgsma30Close_4\", \"sumpctChg+pctChgema10Close_5\", \"pctChg+pctChgsma5Close\", \n",
    "    \"sumpctChg+sma10Close_6\", \"sumpctChg+pctChgsma50Close_5\", \"sumpctChg+bb_maClose_6\", \n",
    "    \"sumpctChglow_1\", \"sumpctChg+ema100Close_5\", \"sumpctChg+ema10Close_3\", \"sumpctChg+pctChgsma5Close_2\", \n",
    "    \"pctChglow\", \"sumpctChgvolume_3\", \"sumpctChgema100_3\", \"sumpctChgsma10_4\", \"sumpctChgsma10_2\", \n",
    "    \"sumpctChg+ema30Close_1\", \"pctChgema50\", \"sumpctChgsma5_2\", \"sumpctChg+pctChgema5Close_1\", \"pctChghigh\", \n",
    "    \"pctChg+sma30Close\", \"pctChgVix\", \"sumpctChgema20_3\", \"sumpctChg+bb_maClose_4\", \"sumpctChg+ema50Close_5\", \n",
    "    \"sumpctChg+sma20Close_5\", \"pctChg+pctChgsma100Close\", \"sumpctChgema20_2\", \"sumpctChg+pctChgema5Close_5\", \n",
    "    \"pctChgema30\", \"sumpctChg+sma5Close_6\", \"sumpctChg+ema50Close_3\", \"sumpctChg+pctChgema30Close_1\", \n",
    "    \"sumpctChgema30_4\", \"sumpctChgema5_3\", 'pctChgclose', 'pctChgema10', 'pctChgema20', 'pctChgema100',\n",
    "]\n",
    "# target_features = ['pctChgclose-3','pctChgclose-2','pctChgclose-1','pctChgclose-0','pctChgclose+1','pctChgclose+2','pctChgclose+3','pctChgclose+4','pctChgclose+5','pctChgclose+6']\n",
    "# target_features = ['pctChgclose+1','pctChgclose+2']\n",
    "# target_features = ['sumPctChgclose+1', 'sumPctChgclose+2', 'sumPctChgclose+3', 'sumPctChgclose+4', 'sumPctChgclose+5', 'sumPctChgclose+6']\n",
    "target_features = ['pctChgclose-14', 'pctChgclose-13', 'pctChgclose-12', 'pctChgclose-11', 'pctChgclose-10', 'pctChgclose-9', 'pctChgclose-8', 'pctChgclose-7', 'pctChgclose-6', 'pctChgclose-5', 'pctChgclose-4', 'pctChgclose-3', 'pctChgclose-2', 'pctChgclose-1', 'pctChgclose-0', 'pctChgclose+1', 'pctChgclose+2', 'pctChgclose+3', 'pctChgclose+4', 'pctChgclose+5', 'pctChgclose+6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoder_initial_weights(model):\n",
    "    initial_weights = {}\n",
    "    for layer in model.layers:\n",
    "        if 'input' in layer.name: \n",
    "            continue\n",
    "        print(layer.name)\n",
    "        initial_weights[layer.name] = deepcopy(layer.get_weights())\n",
    "    return initial_weights\n",
    "\n",
    "model = create_modelAE(len(features))\n",
    "decoder_weights = save_decoder_initial_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "# x = np.array(x)\n",
    "# x = x.reshape(1,1,22)\n",
    "# print(x.shape)\n",
    "# indices = [12, 11, 10, 9, 8, 21, 20, 19, 18, 17, 16, 15, 14, 7, 6, 0, 1, 2, 3, 4, 5]\n",
    "# print(x[:,:,indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "X_train, y_train, X_test, y_test = training_dict['first']\n",
    "X_train_filtered = filter_by_features(X_train, features, feature_dict)\n",
    "X_test_filtered = filter_by_features(X_test, features, feature_dict)\n",
    "y_train_filtered = filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "print(X_train_filtered.shape)\n",
    "\n",
    "# learning_rates = [.0001,0.001, 0.01, 0.1]\n",
    "# batch_sizes = [10, 20, 50, 100]\n",
    "learning_rates = [.01]\n",
    "batch_sizes = [100]\n",
    "\n",
    "\n",
    "best_score = np.inf\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        # Build and compile the model\n",
    "        test_model = deepcopy(model)\n",
    "        test_model.compile(optimizer=Adam(learning_rate=lr), loss=lambda y_true, y_pred: custom_loss_function(y_true, y_pred, 15, 1.0))\n",
    "\n",
    "        # Callbacks\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{lr}_batch{batch}_first\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        test_model.fit(X_train_filtered, y_train_filtered, \n",
    "                  validation_data=(X_test_filtered, y_test_filtered),\n",
    "                  epochs=100,  # Adjust as needed\n",
    "                  batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback, early_stopping],\n",
    "                  verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        score = test_model.evaluate(X_test_filtered, y_test_filtered, verbose=1)\n",
    "\n",
    "        # Update best score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch\n",
    "            model = deepcopy(test_model)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Batch Size: {batch}, Score: {score}\")\n",
    "\n",
    "# Print best configuration\n",
    "print(f\"Best Score: {best_score}, Learning Rate: {best_lr}, Batch Size: {best_batch_size}\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=best_lr), loss='mae')\n",
    "for layer in model.layers:\n",
    "    if 'freeze' in layer.name and '1' in layer.name:\n",
    "        print(layer.name)\n",
    "        layer.trainable = False\n",
    "model.save('path_to_my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('path_to_my_model2.h5', custom_objects={'custom_loss_function': lambda y_true, y_pred: custom_loss_function(y_true, y_pred, past_steps=15, future_weight=1.0)})\n",
    "for layer in model.layers:\n",
    "    if 'input' in layer.name:\n",
    "        continue\n",
    "    if '1' not in layer.name or 'restore' in layer.name:\n",
    "        print(\"restoring weights for layer {}\".format(layer.name))\n",
    "        layer.set_weights(decoder_weights[layer.name])\n",
    "X_train, y_train, X_test, y_test = training_dict['second']\n",
    "X_train_filtered = filter_by_features(X_train, features, feature_dict)\n",
    "X_test_filtered = filter_by_features(X_test, features, feature_dict)\n",
    "y_train_filtered = filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "print(X_train_filtered.shape)\n",
    "\n",
    "# learning_rates = [.0001,0.001, 0.01, 0.1]\n",
    "# batch_sizes = [10, 20, 50, 100]\n",
    "learning_rates = [.01]\n",
    "batch_sizes = [20]\n",
    "\n",
    "\n",
    "best_score = np.inf\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        # Build and compile the model\n",
    "        test_model = deepcopy(model)\n",
    "        test_model.compile(optimizer=Adam(learning_rate=lr), loss=lambda y_true, y_pred: custom_loss_function(y_true, y_pred, 15, 1.0))\n",
    "\n",
    "        # Callbacks\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{lr}_batch{batch}_second\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        test_model.fit(X_train_filtered, y_train_filtered, \n",
    "                  validation_data=(X_test_filtered, y_test_filtered),\n",
    "                  epochs=100,  # Adjust as needed\n",
    "                  batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback, early_stopping],\n",
    "                  verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        score = test_model.evaluate(X_test_filtered, y_test_filtered, verbose=1)\n",
    "\n",
    "        # Update best score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch\n",
    "            model = deepcopy(test_model)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Batch Size: {batch}, Score: {score}\")\n",
    "\n",
    "# Print best configuration\n",
    "print(f\"Best Score: {best_score}, Learning Rate: {best_lr}, Batch Size: {best_batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if 'freeze' in layer.name and '2' in layer.name:\n",
    "        print(layer.name)\n",
    "        layer.trainable = False\n",
    "model.compile(optimizer=Adam(learning_rate=best_lr), loss='mae')\n",
    "model.save('path_to_my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('path_to_my_model2.h5',custom_objects={'rmse': rmse})\n",
    "for layer in model.layers:\n",
    "    if 'input' in layer.name:\n",
    "        continue\n",
    "    if '2' not in layer.name and '1' not in layer.name or 'restore' in layer.name:\n",
    "        layer.set_weights(decoder_weights[layer.name])\n",
    "        print(\"restoring weights for layer {}\".format(layer.name))\n",
    "\n",
    "X_train, y_train, X_test, y_test = training_dict['third']\n",
    "X_train_filtered = filter_by_features(X_train, features, feature_dict)\n",
    "X_test_filtered = filter_by_features(X_test, features, feature_dict)\n",
    "y_train_filtered = filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "\n",
    "# learning_rates = [.0001,0.001, 0.01, 0.1]\n",
    "# batch_sizes = [10, 20, 50, 100]\n",
    "learning_rates = [.01]\n",
    "batch_sizes = [50]\n",
    "\n",
    "\n",
    "best_score = np.inf\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        # Build and compile the model\n",
    "        test_model = deepcopy(model)\n",
    "        test_model.compile(optimizer=Adam(learning_rate=lr), loss=lambda y_true, y_pred: custom_loss_function(y_true, y_pred, 15, 1.0))\n",
    "\n",
    "        # Callbacks\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{lr}_batch{batch}_third\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        test_model.fit(X_train_filtered, y_train_filtered, \n",
    "                  validation_data=(X_test_filtered, y_test_filtered),\n",
    "                  epochs=100,  # Adjust as needed\n",
    "                  batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback, early_stopping],\n",
    "                  verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        score = test_model.evaluate(X_test_filtered, y_test_filtered, verbose=1)\n",
    "\n",
    "        # Update best score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch\n",
    "            model = deepcopy(test_model)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Batch Size: {batch}, Score: {score}\")\n",
    "\n",
    "# Print best configuration\n",
    "print(f\"Best Score: {best_score}, Learning Rate: {best_lr}, Batch Size: {best_batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if 'freeze' in layer.name and '3' in layer.name:\n",
    "        print(layer.name)\n",
    "        layer.trainable = False\n",
    "model.compile(optimizer=Adam(learning_rate=best_lr), loss='mae')\n",
    "model.save('path_to_my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "def eval_model(X_test, y_test_old, model):\n",
    "\n",
    "    predicted_y_old = model.predict(X_test)\n",
    "    predicted_y_old = np.squeeze(predicted_y_old, axis=-1)\n",
    "\n",
    "    print(predicted_y_old.shape)\n",
    "\n",
    "    predicted_y_old = predicted_y_old[:,-6:]\n",
    "    print(predicted_y_old.shape)\n",
    "    y_test_old = y_test_old[:,-6:]\n",
    "    \n",
    "    predicted_y = np.cumsum(predicted_y_old, axis=1)\n",
    "    y_test = np.cumsum(y_test_old, axis=1)\n",
    "   \n",
    "\n",
    "    num_days = predicted_y.shape[1]  # Assuming this is the number of days\n",
    "    print(num_days)\n",
    "    results = pd.DataFrame(predicted_y, columns=[f'predicted_{i+1}' for i in range(num_days)])\n",
    "\n",
    "    for i in range(num_days):\n",
    "        results[f'real_{i+1}'] = y_test[:, i]\n",
    "\n",
    "    # Generate output string with accuracies\n",
    "    output_string = f\"Cluster Number:\\n\"\n",
    "    for i in range(num_days):\n",
    "        results['same_day'] = ((results[f'predicted_{i+1}'] > 0) & (results[f'real_{i+1}'] > 0)) | \\\n",
    "                ((results[f'predicted_{i+1}'] < 0) & (results[f'real_{i+1}'] < 0))\n",
    "        accuracy = round(results['same_day'].mean() * 100,2)\n",
    "\n",
    "        output_string += (\n",
    "            f\"Accuracy{i+1}D {accuracy}% \"\n",
    "            f\"PredictedRet: {results[f'predicted_{i+1}'].mean()} \"\n",
    "            f\"ActRet: {results[f'real_{i+1}'].mean()}\\n\"\n",
    "        )\n",
    "    \n",
    "    output_string += f\"Train set length: {len(X_train_filtered)} Test set length: {len(y_test)}\\n\"\n",
    "\n",
    "    return output_string, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('path_to_my_model2.h5',custom_objects={'rmse': rmse})\n",
    "for layer in model.layers:\n",
    "    if 'restore' in layer.name:\n",
    "        print(\"restoring weights for layer {}\".format(layer.name))\n",
    "        layer.set_weights(decoder_weights[layer.name])\n",
    "\n",
    "X_train, y_train, X_test, y_test = training_dict['last']\n",
    "X_train_filtered = filter_by_features(X_train, features, feature_dict)\n",
    "X_test_filtered = filter_by_features(X_test, features, feature_dict)\n",
    "y_train_filtered = filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "\n",
    "# learning_rates = [.0001,0.001, 0.01, 0.1]\n",
    "# batch_sizes = [10, 20, 50, 100]\n",
    "learning_rates = [.01]\n",
    "batch_sizes = [10]\n",
    "\n",
    "\n",
    "best_score = np.inf\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        # Build and compile the model\n",
    "        test_model = deepcopy(model)\n",
    "        test_model.compile(optimizer=Adam(learning_rate=lr), loss=lambda y_true, y_pred: custom_loss_function(y_true, y_pred, 15, 1.1))\n",
    "\n",
    "        # Callbacks\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{lr}_batch{batch}_tuned\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        test_model.fit(X_train_filtered, y_train_filtered, \n",
    "                  validation_data=(X_test_filtered, y_test_filtered),\n",
    "                  epochs=250,  # Adjust as needed\n",
    "                  batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback, early_stopping],\n",
    "                  verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        # score = test_model.evaluate(X_test_filtered, y_test_filtered, verbose=1)\n",
    "\n",
    "        # Update best score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch\n",
    "            model = deepcopy(test_model)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Batch Size: {batch}, Score: {score}\")\n",
    "\n",
    "# Print best configuration\n",
    "print(f\"Best Score: {best_score}, Learning Rate: {best_lr}, Batch Size: {best_batch_size}\")\n",
    "\n",
    "\n",
    "# val_loss_tuned = model.evaluate(X_test_filtered, y_test_filtered)\n",
    "# print(f'Validation loss: {val_loss_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTunedAccuracy, results_tuned = eval_model(X_test_filtered, y_test_filtered, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[0, 1]\n",
      "(314, 15, 39)\n",
      "(314, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 00:20:55.360049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:55.361026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:55.361705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:55.477330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:55.478057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:55.478757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:55.679420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:55.680565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:55.681232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:55.792832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:55.793562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:55.794197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 25 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 00:20:56.060098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:56.061219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:56.061944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:56.170382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:56.171598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:56.172373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:56.796856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:56.797899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:56.798770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:56.903029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:56.903838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:56.904564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:57.423678: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2024-01-18 00:20:57.423732: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/20 [=======================>......] - ETA: 0s - loss: 2.6117 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 00:20:58.382405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:58.383271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:58.384060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:58.487196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:20:58.487927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:20:58.488610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:20:58.567320: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2024-01-18 00:20:58.567362: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 29ms/step - loss: 2.4880 - val_loss: 1.8276\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.4178 - val_loss: 1.1211\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.9070 - val_loss: 0.7785\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6587 - val_loss: 0.6194\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5413 - val_loss: 0.5370\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4828 - val_loss: 0.4922\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4390 - val_loss: 0.4762\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4258 - val_loss: 0.4475\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4034 - val_loss: 0.4354\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3935 - val_loss: 0.4252\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3831 - val_loss: 0.4203\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3788 - val_loss: 0.4185\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3754 - val_loss: 0.4106\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3688 - val_loss: 0.4077\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3671 - val_loss: 0.4057\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3664 - val_loss: 0.4083\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3657 - val_loss: 0.4034\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3612 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3637 - val_loss: 0.4028\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3613 - val_loss: 0.4010\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3613 - val_loss: 0.3990\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3551 - val_loss: 0.3989\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3544 - val_loss: 0.4003\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3572 - val_loss: 0.4013\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3537 - val_loss: 0.4044\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3539 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3553 - val_loss: 0.4008\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3547 - val_loss: 0.3987\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3534 - val_loss: 0.4011\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3521 - val_loss: 0.3992\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3484 - val_loss: 0.4036\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3530 - val_loss: 0.4014\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3490 - val_loss: 0.4017\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3489 - val_loss: 0.4053\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3546 - val_loss: 0.4056\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3534 - val_loss: 0.4125\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3569 - val_loss: 0.4036\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3576 - val_loss: 0.4012\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3494 - val_loss: 0.4011\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3482 - val_loss: 0.4053\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3459 - val_loss: 0.4067\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.3466 - val_loss: 0.4169\n",
      "Epoch 43/100\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.3488Restoring model weights from the end of the best epoch: 28.\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3509 - val_loss: 0.4019\n",
      "Epoch 43: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 00:21:05.755934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:21:05.756891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:21:05.757555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:21:05.870565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:21:05.871419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:21:05.872091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Batch Size: 16, Score: 0.08893406391143799\n",
      "Best Score: 0.08893406391143799, Learning Rate: 0.001, Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 00:21:06.554490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:21:06.556543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:21:06.557591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:21:06.667425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-18 00:21:06.668227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-18 00:21:06.668927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-18 00:21:06.751834: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2024-01-18 00:21:06.751898: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 2080 Ti\" frequency: 1545 num_cores: 68 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11080\" } environment { key: \"cudnn\" value: \"8600\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 5767168 shared_memory_size_per_multiprocessor: 65536 memory_size: 9784721408 bandwidth: 616000000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 2ms/step\n",
      "(87, 2)\n",
      "(87, 2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "benchmark_model = create_autoencoder(15,len(target_features),len(features))\n",
    "X_train, y_train, X_test, y_test = training_dict['last']\n",
    "X_train_filtered = filter_by_features(X_train, features, feature_dict)\n",
    "X_test_filtered = filter_by_features(X_test, features, feature_dict)\n",
    "y_train_filtered = filter_y_by_features(y_train, target_features, y_feature_dict)\n",
    "y_test_filtered = filter_y_by_features(y_test, target_features, y_feature_dict)\n",
    "\n",
    "print(X_train_filtered.shape)\n",
    "print(y_train_filtered.shape)\n",
    "\n",
    "# learning_rates = [.0001,0.001, 0.01, 0.1]\n",
    "# batch_sizes = [10, 20, 50, 100]\n",
    "\n",
    "learning_rates = [.001]\n",
    "batch_sizes = [16]\n",
    "\n",
    "\n",
    "best_score = np.inf\n",
    "best_lr = None\n",
    "best_batch_size = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        # Build and compile the model\n",
    "        test_model = deepcopy(benchmark_model)\n",
    "        test_model.compile(optimizer=Adam(learning_rate=lr), loss='mse')\n",
    "\n",
    "        # Callbacks\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + f\"_lr{lr}_batch{batch}_bench\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        test_model.fit(X_train_filtered, y_train_filtered, \n",
    "                  validation_data=(X_test_filtered, y_test_filtered),\n",
    "                  epochs=100,  # Adjust as needed\n",
    "                  batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback, early_stopping],\n",
    "                  verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        # score = test_model.evaluate(X_test_filtered, y_test_filtered, verbose=1)\n",
    "\n",
    "        # Update best score\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_lr = lr\n",
    "            best_batch_size = batch\n",
    "            benchmark_model = deepcopy(test_model)\n",
    "\n",
    "        print(f\"Learning Rate: {lr}, Batch Size: {batch}, Score: {score}\")\n",
    "\n",
    "# Print best configuration\n",
    "print(f\"Best Score: {best_score}, Learning Rate: {best_lr}, Batch Size: {best_batch_size}\")\n",
    "\n",
    "# val_loss_benchmark = benchmark_model.evaluate(X_test_filtered, y_test_filtered)\n",
    "\n",
    "benchmarkAccuracy, results_benchmark = eval_model(X_test_filtered, y_test_filtered, benchmark_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "import gc\n",
    "clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "def visualize_future_distribution(results):\n",
    "    '''\n",
    "    Create stacked box and whisker plots for the predicted and real values\n",
    "    '''\n",
    "\n",
    "    fig = go.Figure()\n",
    "    print(results.shape)\n",
    "\n",
    "    for i in range(2):\n",
    "\n",
    "        fig.add_trace(go.Box(y=results[f'predicted_{i+1}'], name=f'Predicted {i}')) \n",
    "        fig.add_trace(go.Box(y=results[f'real_{i+1}'], name=f'Real {i}'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Future Performance of Cluster',\n",
    "        xaxis_title='Steps in future',\n",
    "        yaxis_title='Cumulative Percent Change'\n",
    "    ) \n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 5)\n",
      "(201, 13)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Predicted 0",
         "type": "box",
         "xaxis": "x",
         "y": [
          -0.0008150574285537004,
          -0.01983192376792431,
          -0.014002264477312565,
          -0.011027204804122448,
          -0.022423848509788513,
          -0.016733694821596146,
          -0.02130432054400444,
          -0.029782379046082497,
          -0.02921287715435028,
          -0.04181453958153725,
          -0.033170826733112335,
          -0.024453701451420784,
          -0.01733759231865406,
          0.004434544593095779,
          0.027320286259055138,
          -0.03774387389421463,
          -0.04599745199084282,
          -0.03152218088507652,
          -0.0305770430713892,
          -0.0382610447704792,
          -0.03070923127233982,
          0.06645561009645462,
          0.040620967745780945,
          0.05728796869516373,
          0.030516447499394417,
          -0.009198329411447048,
          -0.044349558651447296,
          -0.06507236510515213,
          0.07188491523265839,
          0.08751937001943588,
          0.08448540419340134,
          0.0635661855340004,
          0.033595625311136246,
          -0.01277272216975689,
          -0.06339843571186066,
          0.03142305836081505,
          0.04534626752138138,
          0.022240091115236282,
          -0.0021489239297807217,
          -0.04611313343048096,
          -0.07099231332540512,
          -0.0014782357029616833,
          0.006348014809191227,
          -0.013987936079502106,
          -0.029726045206189156,
          -0.04654031991958618,
          -0.042958930134773254,
          -0.06253252923488617,
          -0.055407069623470306,
          -0.025190947577357292,
          0.012607185170054436,
          0.046941619366407394,
          0.06669247150421143,
          0.06199969723820686,
          -0.0320928655564785,
          -0.0557071715593338,
          -0.05126805230975151,
          -0.04546220228075981,
          -0.03741417080163956,
          0.07991316169500351,
          0.05258236080408096,
          0.021326757967472076,
          -0.022515906020998955,
          0.006905759684741497,
          -0.0053365761414170265,
          -0.015365867875516415,
          -0.010125258006155491,
          0.008248732425272465,
          -0.02007407881319523,
          -0.03777993842959404,
          -0.06496533006429672,
          -0.05131100118160248,
          0.1246572956442833,
          0.06128932163119316,
          0.052248768508434296,
          -0.009484915994107723,
          -0.03802637755870819,
          -0.033532414585351944,
          0.008699140511453152,
          -0.01730387657880783,
          -0.015761764720082283,
          -0.014605746604502201,
          0.011100895702838898,
          0.03871473670005798,
          -0.03934793546795845,
          -0.03570202365517616,
          -0.012672116048634052
         ],
         "yaxis": "y"
        },
        {
         "name": "Real 0",
         "type": "box",
         "xaxis": "x",
         "y": [
          -0.0023693388030841746,
          0.5429695468241843,
          -0.2570423720846442,
          -0.31461303242166155,
          0.21139248203157301,
          0.09625578092321961,
          -0.07551961488467931,
          0.21255517674276392,
          0.09649496811240386,
          0.33863875624168377,
          0.1395111980653739,
          -0.8797003337805778,
          0.6776130274766297,
          0.49622359362600166,
          -0.7973240925271793,
          -0.7446449757849122,
          -0.9521218413114819,
          0.6527047593685305,
          0.36190428420493576,
          -0.02925522523288199,
          1,
          1,
          -1,
          1,
          -0.17022032795852196,
          -0.3268192298479129,
          -0.39402802832309863,
          -1,
          -0.8646480892405678,
          -0.433481231902361,
          -0.9002025147305159,
          -0.5923613702581076,
          0.4002002937724287,
          -0.6032064852454305,
          -0.5858974306100448,
          -0.04245019367570544,
          0.7729094051928981,
          0.174290740136754,
          0.09746179036378261,
          0.5458108773274561,
          -0.4192620647868138,
          1,
          1,
          0.4559334305164592,
          -0.3939481435451069,
          0.9655510612385089,
          0.022527861921988523,
          -0.01508919295763634,
          0.40365363273052773,
          0.6456382791177808,
          1,
          1,
          -0.3771528026265061,
          -0.6561724608722392,
          -0.3912607102284789,
          -1,
          -0.41927855446839485,
          -0.25691867539343244,
          0.9493536406013764,
          -0.9271337870978927,
          0.7553098987323604,
          0.4246063526134063,
          -0.1656177000029629,
          0.39302085731312686,
          0.8680449146161537,
          0.18565823633439052,
          -0.1270301177566924,
          -0.373612385333935,
          0.8982875694838413,
          -0.733628186725022,
          0.9151323899445912,
          -0.48997032741109875,
          -0.7459220480430183,
          1,
          -1,
          -0.7692062431753419,
          1,
          0.5109139661876121,
          0.659158919065275,
          0.3633875506332926,
          -0.20248247207523343,
          0.5706805633222842,
          -1,
          -0.015886200491944898,
          -0.012502311660686148,
          0.23681629041781369,
          0.5164228211029174
         ],
         "yaxis": "y"
        },
        {
         "name": "Predicted 1",
         "type": "box",
         "xaxis": "x",
         "y": [
          -0.0070519037544727325,
          -0.03439672663807869,
          -0.023350387811660767,
          -0.01564151793718338,
          -0.03384469449520111,
          -0.03732229769229889,
          -0.044615406543016434,
          -0.06172005087137222,
          -0.05791689455509186,
          -0.07503074407577515,
          -0.05330140143632889,
          -0.03993606939911842,
          -0.018222006037831306,
          0.0282160434871912,
          0.06250369548797607,
          -0.062070686370134354,
          -0.0823880136013031,
          -0.06585560739040375,
          -0.05673466622829437,
          -0.07282466441392899,
          -0.04242512211203575,
          0.16292810440063477,
          0.10474063456058502,
          0.1592870056629181,
          0.10544297099113464,
          0.028834305703639984,
          -0.04106245934963226,
          -0.08384563773870468,
          0.18092846870422363,
          0.21035534143447876,
          0.20005424320697784,
          0.15273258090019226,
          0.09631161391735077,
          0.0004815952852368355,
          -0.10037325322628021,
          0.05865168571472168,
          0.09625266492366791,
          0.05375257506966591,
          0.014284061267971992,
          -0.06139826774597168,
          -0.10294854640960693,
          0.02089107595384121,
          0.04889894649386406,
          0.014956029132008553,
          -0.015334229916334152,
          -0.04621246084570885,
          -0.033316873013973236,
          -0.12383581697940826,
          -0.10484857857227325,
          -0.0404462069272995,
          0.046702586114406586,
          0.12396162748336792,
          0.15922439098358154,
          0.14420591294765472,
          -0.03307719528675079,
          -0.08635285496711731,
          -0.07754597067832947,
          -0.06677749752998352,
          -0.040702272206544876,
          0.15701888501644135,
          0.11386449635028839,
          0.0629052221775055,
          -0.020659025758504868,
          0.007523628883063793,
          -0.007833351381123066,
          -0.021977659314870834,
          -0.010348372161388397,
          0.02142006903886795,
          -0.036704741418361664,
          -0.07059851288795471,
          -0.1217251867055893,
          -0.0914028137922287,
          0.2841847240924835,
          0.17511476576328278,
          0.15510854125022888,
          0.03385729715228081,
          -0.013199666514992714,
          -0.07041218131780624,
          0.01717093214392662,
          -0.03401239961385727,
          -0.030788462609052658,
          -0.021719876676797867,
          0.026003755629062653,
          0.0837574303150177,
          -0.07280578464269638,
          -0.06336449831724167,
          -0.014888730831444263
         ],
         "yaxis": "y"
        },
        {
         "name": "Real 1",
         "type": "box",
         "xaxis": "x",
         "y": [
          -0.6909663353905955,
          0.540596954402921,
          0.2866727901770343,
          -0.5720083796627162,
          -0.10365258260107074,
          -0.12708777994943632,
          0.020868346188650355,
          0.13693185697993632,
          -0.01950172521727639,
          0.4352662329602994,
          0.4786149790692463,
          -0.7399975564570498,
          -0.20329532644627846,
          1.174767131362164,
          -0.3004190758379129,
          -0.8182973387958433,
          -1.6977893768193937,
          0.8408487560103958,
          1.0155053493562813,
          0.3331460323709797,
          0.9707046009715735,
          1.6071829709322616,
          0,
          0,
          0.8297796720414781,
          -0.4972733073878682,
          -0.7212960521493661,
          -1.394569114618714,
          -1.3758704995139213,
          -1.299316671275378,
          -1.334279010769256,
          -1.493800059090431,
          -0.19297451765346263,
          -0.20245662931270803,
          -1.1899322497280216,
          -0.632784126427851,
          0.7304009181563322,
          0.9482615182697498,
          0.2719918696443585,
          0.6434065039549595,
          0.1272983297437118,
          0.7100423505531371,
          2,
          1.4559334305164593,
          0.06261138286614254,
          0.5710619410969843,
          0.989404835048483,
          0.5896012384027645,
          0.3885437190247862,
          1.0498462161950715,
          1.6465248810842503,
          2,
          0.6228471973734939,
          -1.033843176434337,
          0.6087392897715211,
          -1.3917979963936746,
          -1.4192785544683948,
          -0.6767729906289833,
          0.6920821599140294,
          -1.9271337870978926,
          -0.17309704496948175,
          1.1809534563306152,
          0.25957172960475805,
          0.546011076696596,
          1.2616054751597543,
          1.054895165664006,
          0.05888306776945029,
          -0.5008169431073467,
          1.3562736881049458,
          0.16589292722375992,
          0.1804967719472217,
          0.4264187386054464,
          0.2540779519569817,
          0.2530536385356468,
          0,
          -1.769206243175342,
          0.22973746913249737,
          0.42791935595421055,
          0.636202261116238,
          1.0234516384482548,
          0.1614040888048219,
          0.36792003871558876,
          -0.4285357679795728,
          -1.015886200491945,
          -0.10372451241099725,
          0.22429681036042262,
          0.75356431186211
         ],
         "yaxis": "y"
        },
        {
         "name": "Predicted 0",
         "type": "box",
         "xaxis": "x2",
         "y": [
          0.005514420568943024,
          0.0027382634580135345,
          -0.031179405748844147,
          0.008188044652342796,
          0.007115626707673073,
          -0.002712290734052658,
          -0.005437469109892845,
          -0.0029288306832313538,
          -0.005476728081703186,
          0.00023354962468147278,
          -0.030777141451835632,
          -0.05033431202173233,
          -0.0005719717592000961,
          0.031616419553756714,
          -0.005091411992907524,
          0.0030039511620998383,
          0.000535912811756134,
          -0.034230127930641174,
          0.029423190280795097,
          -0.010364784859120846,
          0.006816431879997253,
          -0.05417448282241821,
          0.014553466811776161,
          0.006466573104262352,
          0.018986599519848824,
          0.031686440110206604,
          -0.0037379637360572815,
          0.04696133732795715,
          0.03781518340110779,
          0.037957027554512024,
          0.021632501855492592,
          0.038804203271865845,
          0.055568210780620575,
          0.03881008177995682,
          -0.03486071899533272,
          0.041929177939891815,
          0.01385350339114666,
          0.01808539591729641,
          0.03544995188713074,
          -0.01395194698125124,
          0.01358882151544094,
          -0.06637034565210342,
          -0.056076906621456146,
          -0.0153077132999897,
          0.008145717903971672,
          0.014476267620921135,
          0.015383442863821983,
          0.01934845931828022,
          0.014355672523379326,
          -0.030518796294927597,
          -0.020982224494218826,
          0.01136682741343975,
          0.037383392453193665,
          0.03746351599693298,
          0.012202812358736992,
          -0.06418085843324661,
          0.0015679467469453812,
          -0.004600288346409798,
          0.1158384308218956,
          0.03295951336622238,
          -0.07536002993583679,
          0.14081606268882751,
          0.01884257234632969,
          -0.04195569455623627,
          0.0696888417005539,
          0.14968658983707428,
          0.16379721462726593,
          -0.05010125786066055,
          0.017049388960003853,
          0.00629180483520031,
          0.009572798386216164,
          0.010829666629433632,
          -0.030951837077736855,
          -0.01554971281439066,
          0.02417050488293171,
          0.013563936576247215,
          0.020783638581633568,
          -0.015524329617619514,
          -0.015152517706155777,
          -0.0017728805541992188,
          0.12858209013938904,
          0.08016607910394669,
          0.019131338223814964,
          -0.009521876461803913,
          -0.022943001240491867,
          0.22749555110931396,
          0.049576692283153534,
          -0.050292499363422394,
          -0.0017200596630573273,
          0.01688709296286106,
          -0.04448043927550316,
          0.002129495143890381,
          0.05522332340478897,
          -0.019605914130806923,
          0.0009493175894021988,
          0.017879782244563103,
          0.037799566984176636,
          0.03455566614866257,
          0.04254383593797684,
          -0.01991043984889984,
          0.04662114381790161,
          -0.0036093611270189285,
          0.023826824501156807,
          0.02712954394519329,
          -0.02738269791007042,
          0.019055431708693504,
          -0.04363185912370682,
          -0.058206573128700256,
          -0.03648674115538597,
          0.03122956119477749,
          -0.01301889680325985,
          0.017531489953398705,
          0.014297017827630043,
          0.01289965771138668,
          -0.020693102851510048,
          -0.02307882159948349,
          -0.030909979715943336,
          0.03081635944545269,
          0.07845968008041382,
          0.00507853738963604,
          0.009175537154078484,
          0.01810588873922825,
          0.0005342531949281693,
          0.03800494223833084,
          -0.00595763698220253,
          -0.015373973175883293,
          0.14257226884365082,
          0.005675852298736572,
          -0.03403134271502495,
          -0.038974158465862274,
          -0.0354616716504097,
          0.025623062625527382,
          0.04244425892829895,
          0.08407603949308395,
          0.07130957394838333,
          0.04607955366373062,
          0.24126702547073364,
          0.18199099600315094,
          -0.011066801846027374,
          0.0029866360127925873,
          -0.020486634224653244,
          0.05686970800161362,
          -0.023153135553002357,
          0.04484383016824722,
          0.055445343255996704,
          -0.005617406219244003,
          0.039506152272224426,
          0.034217819571495056,
          0.021813133731484413,
          0.054054297506809235,
          0.001361733302474022,
          -0.0012126658111810684,
          0.025292227044701576,
          0.027398599311709404,
          0.020287996158003807,
          -0.033140379935503006,
          -0.00746532529592514,
          -0.06286469101905823,
          -0.01107005961239338,
          -0.014061074703931808,
          0.023428549990057945,
          0.019606543704867363,
          0.018063073977828026,
          0.01582401804625988,
          0.011720674112439156,
          0.05519004166126251,
          0.0290296021848917,
          0.013270648196339607,
          0.014003252610564232,
          0.032928064465522766,
          -0.025946151465177536,
          -0.010039398446679115,
          0.03423544019460678,
          -0.04224548488855362,
          -0.02049138955771923,
          0.04116258770227432,
          0.030847808346152306,
          0.07364518195390701,
          0.02085673250257969,
          0.0017143767327070236,
          -0.04398547112941742,
          0.025362705811858177,
          0.003672465682029724,
          0.0833522230386734,
          0.034247808158397675,
          0.2234269678592682,
          0.1528179794549942,
          -0.04296325892210007,
          -0.07168257236480713,
          -0.00416259840130806,
          -0.02166750282049179,
          0.04276462644338608,
          0.01932167448103428,
          0.015880094841122627,
          -0.0055731795728206635,
          -0.010744997300207615,
          0.03988363593816757,
          0.0006019268184900284,
          0.09291499853134155,
          0.006261361762881279,
          0.0005230177193880081
         ],
         "yaxis": "y2"
        },
        {
         "name": "Real 0",
         "type": "box",
         "xaxis": "x2",
         "y": [
          0.159741736610641,
          0.2671208721207905,
          0.037003388223405445,
          0.7417216274125243,
          0.606645906148696,
          0.014005212424922414,
          -0.16948762777622145,
          0.4627359925221703,
          -0.6842714728115343,
          -0.9615489533526314,
          -0.6194707221516623,
          0.6103329217981122,
          0.14880353023027992,
          0.7574728636854214,
          0.3032239584896389,
          0.597482924667757,
          0.5101800794793434,
          -1,
          -1,
          -0.15917909322245763,
          0.5550475832815532,
          0.1649949797843552,
          0.5828473820689877,
          -0.13365130584872648,
          0.10608373620113794,
          0.4759591923349177,
          -0.20318816821686803,
          -0.3836093368712614,
          0.19808775906523038,
          -0.08358501171969025,
          -0.16879393258087438,
          0.1622733820383905,
          0.1314099133631723,
          -0.6310357627963155,
          -0.2174218267087505,
          0.894332519120347,
          0.27523513012068307,
          1,
          0.5490481289724141,
          -0.030168949703636223,
          0.5355164523058462,
          -0.9048675656098922,
          0.9718278240598652,
          -0.14368467419498804,
          0.4651988909512069,
          -0.07614238831691059,
          0.5640067389816492,
          0.10408959037407343,
          -0.11875223652378332,
          0.6759041818037934,
          1,
          0.8127695215706155,
          1,
          -0.223959959361155,
          -0.08438579304348226,
          0.372414558019872,
          -0.07214940671525547,
          -0.007841328811076832,
          -1,
          -0.6466783787567043,
          -0.6010650409003571,
          1,
          -0.7489061514774111,
          -1,
          1,
          0.057177445994469465,
          -0.6349582421909656,
          1,
          0.3118487062520686,
          0.48456617128198176,
          0.4775323965668563,
          0.40589216105344483,
          -0.49958951378464944,
          -1,
          -0.7878379255080901,
          -0.29073861529042394,
          0.5289401011745231,
          -0.17829031320325064,
          -0.629534346892541,
          0.30056128626996503,
          0.7049089052445899,
          -1,
          -0.35809314001673975,
          0.5835039601169881,
          -0.5697460298490044,
          -0.41589211615657523,
          -0.9201666156510124,
          -1,
          0.8276983425398008,
          0.45471028080326337,
          -0.6182827487405491,
          0.5901599210635969,
          -0.45540175583928094,
          0.18280575393562698,
          0.8238789868295666,
          0.45647926254391175,
          0.7837244932195117,
          -0.2437225433243221,
          -0.33825846868905773,
          0.2554031285432298,
          0.9281422187670333,
          -0.06079032238502096,
          -0.012380079345811689,
          0.9414730834215026,
          0.13549316203610184,
          0.721659140903111,
          -0.8054282904846104,
          0.7703185769484182,
          -1,
          0.4237983534867972,
          0.2488569192315371,
          0.6382118182478118,
          0.2631742384717633,
          0.5025091582920623,
          -0.11753771243436814,
          1,
          0.9155374157905527,
          1,
          0.26795032970511284,
          -0.6680686262988698,
          -0.2587382363289026,
          0.3632921130523922,
          0.5743385380787959,
          0.5872442955808741,
          -0.7557126136360556,
          -0.26661768937384456,
          1,
          -0.8783797353728138,
          -1,
          0.22708317877488074,
          1,
          -0.9519423399262489,
          0.5381376818140241,
          1,
          -0.09998939181121833,
          -0.9638583327611805,
          0.11145172165541309,
          -1,
          -1,
          -0.7424181399533545,
          0.0027199905597975944,
          -0.6239120808556371,
          -0.3318233749344049,
          1,
          0.07425591345193344,
          -1,
          -1,
          -0.17015979202525677,
          0.10242525361735816,
          -0.10547891693646966,
          -0.5272513084242711,
          -0.6440872370945279,
          0.6205798434004792,
          0.2260861425996579,
          0.3404122441194398,
          0.06977491667467701,
          0.41898783968889486,
          0.060491644371006174,
          1,
          0.7395204445264745,
          0.6587295522834389,
          0.9343781888029504,
          -0.0751718490385134,
          -0.04810662339070041,
          -0.09397925819983402,
          -0.21285327663723203,
          0.2066328284054403,
          0.41397195900622935,
          -0.5625817733412467,
          0.1549631866858353,
          -0.45249415861203185,
          1,
          1,
          0.44216020395411265,
          1,
          -0.9577690912960994,
          0.0387856985611972,
          0.06892060562581921,
          -1,
          -0.21898556365601227,
          -1,
          -1,
          1,
          0.3812667888864722,
          -1,
          0.21124692952468374,
          -1,
          0.2296797923216649,
          0.2949595303801359,
          0.8239060013230082,
          -0.4238216991796907,
          0.4172349500718179,
          0.7738854692085909,
          -0.7191930115606201,
          -0.09540146398301066,
          0.5632009419611165,
          1,
          0.008783142983852792,
          0.4333025014343442,
          -0.32720585224787285,
          -1
         ],
         "yaxis": "y2"
        },
        {
         "name": "Predicted 1",
         "type": "box",
         "xaxis": "x2",
         "y": [
          0.013362491503357887,
          0.015740467235445976,
          -0.0325823649764061,
          0.023053500801324844,
          0.02447725459933281,
          0.007545849308371544,
          -0.0007497482001781464,
          0.019961318001151085,
          0.0006333384662866592,
          0.011548461392521858,
          -0.044646453112363815,
          -0.059729404747486115,
          0.011919546872377396,
          0.07303405553102493,
          0.025675691664218903,
          0.0309563260525465,
          0.030174272134900093,
          0.03037949651479721,
          0.07114791125059128,
          0.017343107610940933,
          0.023488139733672142,
          -0.03482078015804291,
          0.03886869549751282,
          0.016439370810985565,
          0.036813538521528244,
          0.06155427545309067,
          0.008644511923193932,
          0.0956597700715065,
          0.08332369476556778,
          0.08007439225912094,
          0.05691870301961899,
          0.07928498089313507,
          0.10803502798080444,
          0.08888746798038483,
          -0.005666924640536308,
          0.06992875784635544,
          0.03540492057800293,
          0.05735349655151367,
          0.08017410337924957,
          0.009152987040579319,
          0.05161522328853607,
          -0.08106803148984909,
          -0.03870244324207306,
          -0.0232599638402462,
          0.02184901013970375,
          0.03307648375630379,
          0.03538186848163605,
          0.045313239097595215,
          0.038842566311359406,
          0.0036191754043102264,
          -0.0005365107208490372,
          0.05221258103847504,
          0.07854408025741577,
          0.0822896659374237,
          0.05010680854320526,
          -0.05251334607601166,
          0.012803412973880768,
          0.00022125430405139923,
          0.15585772693157196,
          0.0781785100698471,
          -0.06257305294275284,
          0.1564093381166458,
          0.03569129854440689,
          -0.05386582762002945,
          0.1305818110704422,
          0.20767585933208466,
          0.19496040046215057,
          -0.022414403036236763,
          0.0510890856385231,
          0.03929217904806137,
          0.04143489897251129,
          0.042870618402957916,
          -0.030833395197987556,
          0.046151258051395416,
          0.06935384124517441,
          0.0482354536652565,
          0.05042625591158867,
          0.0014536380767822266,
          -0.019034486263990402,
          0.001200202852487564,
          0.16278111934661865,
          0.08462806791067123,
          0.045261699706315994,
          -0.004871672950685024,
          -0.042830921709537506,
          0.26000675559043884,
          0.10150792449712753,
          -0.025955351069569588,
          0.025003893300890923,
          0.05110381543636322,
          -0.05007515475153923,
          0.0194369088858366,
          0.09793676435947418,
          -0.015913372859358788,
          0.01030656322836876,
          0.057701192796230316,
          0.08684810996055603,
          0.07636179774999619,
          0.09581013023853302,
          0.021081313490867615,
          0.08923286944627762,
          0.040323227643966675,
          0.05374366044998169,
          0.06980191916227341,
          -0.00503922812640667,
          0.05943933129310608,
          -0.04447674751281738,
          -0.034649111330509186,
          -0.04474686086177826,
          0.06828656792640686,
          0.013129685074090958,
          0.045516353100538254,
          0.03307901322841644,
          0.04035266488790512,
          -0.027652421966195107,
          0.017516866326332092,
          0.020322909578680992,
          0.07512594759464264,
          0.11860605329275131,
          0.02590683475136757,
          0.01788545399904251,
          0.042826056480407715,
          0.03463682532310486,
          0.07048143446445465,
          -0.0016508400440216064,
          -0.01777937076985836,
          0.17121203243732452,
          0.028729571029543877,
          -0.043180596083402634,
          -0.01239624060690403,
          0.037390708923339844,
          0.07140375673770905,
          0.08847963064908981,
          0.14704065024852753,
          0.13757506012916565,
          0.06689906865358353,
          0.3029606342315674,
          0.2296275496482849,
          0.01872575469315052,
          0.01984218694269657,
          -0.014344053342938423,
          0.11885067075490952,
          0.0333888903260231,
          0.09614292532205582,
          0.07493405789136887,
          -0.012089261785149574,
          0.08946504443883896,
          0.07264479994773865,
          0.05931495130062103,
          0.11343465745449066,
          0.052105627954006195,
          0.025471307337284088,
          0.05905134230852127,
          0.0551736019551754,
          0.05469531565904617,
          -0.016827335581183434,
          0.015478136017918587,
          -0.06270693242549896,
          0.021188220009207726,
          0.016722416505217552,
          0.05642648786306381,
          0.049583565443754196,
          0.0446220263838768,
          0.04278089478611946,
          0.02978069707751274,
          0.1148974820971489,
          0.07747157663106918,
          0.06210421770811081,
          0.04488278925418854,
          0.04020591080188751,
          -0.025631150230765343,
          0.013753790408372879,
          0.09051153063774109,
          -0.002507627010345459,
          0.05342777073383331,
          0.08789976686239243,
          0.06567081063985825,
          0.10690666735172272,
          0.04435965046286583,
          0.013578850775957108,
          0.007557213306427002,
          0.058720581233501434,
          0.03906567394733429,
          0.1703619360923767,
          0.08112496882677078,
          0.23676662147045135,
          0.15391801297664642,
          -0.04471705108880997,
          -0.09550933539867401,
          0.0006995406001806259,
          -0.04464810714125633,
          0.09923306852579117,
          0.06792513281106949,
          0.04005841165781021,
          0.013590006157755852,
          0.03020799160003662,
          0.08575566112995148,
          0.031189408153295517,
          0.14828956127166748,
          0.067019984126091,
          0.02016713097691536
         ],
         "yaxis": "y2"
        },
        {
         "name": "Real 1",
         "type": "box",
         "xaxis": "x2",
         "y": [
          -0.16511796488336072,
          0.30710070530770855,
          0.30412426034419593,
          1.0593321971499583,
          1.3483675335612202,
          0.6206511185736183,
          -0.15548241535129903,
          0.6497826845604995,
          -0.22153548028936404,
          0.03845104664736865,
          -1.5810196755042938,
          -0.009137800353550163,
          -0.3169850636119728,
          0.9062763939157014,
          1.0606968221750603,
          0.9007068831573959,
          1.1076630041471005,
          -2,
          -2,
          -1.1591790932224577,
          0.39586849005909563,
          0.7200425630659084,
          0.8446150972391178,
          0.4491960762202612,
          0.15260447738978553,
          0.5820429285360557,
          -0.07902538639644638,
          0.21676889332837856,
          -0.18552157780603104,
          0.11450274734554013,
          -0.2523789443005646,
          0.2091438996534045,
          0.2936832954015628,
          -0.49962584943314314,
          -0.8484575895050659,
          0.6769106924115964,
          0.0364856371740421,
          0.1627427593398163,
          1.549048128972414,
          0.5188791792687778,
          0.50534750260221,
          -0.369351113304046,
          0.066960258449973,
          -0.5363106358368268,
          0.3215142167562189,
          -0.41435719592688125,
          0.48786435066473866,
          0.6680963293557226,
          -0.014662646149709885,
          1.6759041818037934,
          1.6759041818037934,
          1.8127695215706154,
          1.0244569300312518,
          0.776040040638845,
          -0.30834575240463724,
          0.28802876497638974,
          0.058284179234437516,
          -0.07999073552633229,
          -2,
          -1.6466783787567043,
          -1.2477434196570614,
          0.39893495909964294,
          0.25109384852258887,
          -1.7489061514774111,
          0.08079670602445799,
          1.0571774459944694,
          -0.5777807961964961,
          1.593822285293645,
          0.20733645905516465,
          0.7964148775340504,
          0.9620985678488381,
          0.8834245576203011,
          -0.09369735273120461,
          -2,
          -1.78783792550809,
          -1.078576540798514,
          0.23820148588409912,
          0.35064978797127244,
          -0.8078246600957916,
          -0.3289730606225759,
          -0.29509109475541007,
          -0.29509109475541007,
          -1.3580931400167398,
          0.5311474795647286,
          0.013757930267983776,
          0.5841078838434248,
          -0.925306999423804,
          -1.9201666156510124,
          -0.1723016574601992,
          1.282408623343064,
          -0.16357246793728575,
          -0.028122827676952178,
          0.41908357254477474,
          0.5666043232678302,
          1.0066847407651935,
          0.2712825645389061,
          1.2402037557634233,
          0.5400019498951896,
          -0.8405577831215526,
          -0.08285534014582796,
          1.183545347310263,
          0.8673518963820124,
          0.29188391549552894,
          1.9233649502261623,
          1.0769662454576046,
          0.8571523029392129,
          -0.08376914958149939,
          -0.03510971353619219,
          -0.2296814230515818,
          0.9986696762454855,
          0.6726552727183343,
          0.16214939273178053,
          0.9013860567195751,
          0.7656833967638257,
          0.38497144585769416,
          1.5159663623111173,
          1.9155374157905527,
          1.9155374157905527,
          1.267950329705113,
          -0.4001182965937569,
          -0.4134330443688826,
          0.10455387672348959,
          0.11116423023815947,
          1.1615828336596699,
          -0.16846831805518148,
          -1.0223303030099,
          0.25416518951002964,
          0.12162026462718623,
          -1.8783797353728138,
          -0.17994643371637845,
          1.2270831787748808,
          0.04805766007375112,
          -0.4138046581122248,
          1.4369805647295049,
          0.9000106081887816,
          -1.0638477245723987,
          1.1114517216554132,
          -0.8885482783445869,
          -2,
          -1.7424181399533545,
          -0.7396981493935569,
          -1.623912080855637,
          -0.9557354557900419,
          0.6681766250655952,
          0.6779241750607938,
          -0.9257440865480666,
          -1.027938420136721,
          -1.1701597920252569,
          -0.06773453840789861,
          0.37375464341378833,
          -0.6327302253607408,
          -1.171338545518799,
          -0.02350739369404864,
          -0.1409440511623475,
          0.5664983867190977,
          0.4101871607941168,
          -0.4215703512388155,
          -0.025442974778818093,
          1.0604916443710062,
          1.7395204445264745,
          1.3982499968099134,
          0.3822058522841748,
          0.859206339764437,
          -0.1232784724292138,
          -0.14208588159053442,
          -0.8923467625986785,
          -0.006220448231791714,
          0.6206047874116697,
          -0.14860981433501735,
          -0.4076185866554114,
          -0.29753097192619654,
          1.0125773238182096,
          2,
          1.4421602039541126,
          1.4421602039541126,
          0.04223090870390056,
          -0.9189833927349023,
          0.1077063041870164,
          -0.9310793943741807,
          -1.2189855636560123,
          -2,
          -2,
          1.2057869113396402,
          1.3812667888864723,
          -0.6187332111135277,
          -0.7887530704753163,
          -0.7887530704753163,
          1.0368560876551114,
          0.5246393227018008,
          1.1188655317031442,
          0.40008430214331747,
          1.3565570297568104,
          0.4509039018820056,
          0.054692457647970816,
          -0.8145944755436307,
          0.18223903340035041,
          1.5632009419611164,
          1.0087831429838527,
          1.0372852198180267,
          0.10609664918647133,
          -1.327205852247873
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3f7cfd85-12df-4bfc-a95e-d621a07756e2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3f7cfd85-12df-4bfc-a95e-d621a07756e2\")) {                    Plotly.newPlot(                        \"3f7cfd85-12df-4bfc-a95e-d621a07756e2\",                        [{\"name\":\"Predicted 0\",\"y\":[-0.0008150574285537004,-0.01983192376792431,-0.014002264477312565,-0.011027204804122448,-0.022423848509788513,-0.016733694821596146,-0.02130432054400444,-0.029782379046082497,-0.02921287715435028,-0.04181453958153725,-0.033170826733112335,-0.024453701451420784,-0.01733759231865406,0.004434544593095779,0.027320286259055138,-0.03774387389421463,-0.04599745199084282,-0.03152218088507652,-0.0305770430713892,-0.0382610447704792,-0.03070923127233982,0.06645561009645462,0.040620967745780945,0.05728796869516373,0.030516447499394417,-0.009198329411447048,-0.044349558651447296,-0.06507236510515213,0.07188491523265839,0.08751937001943588,0.08448540419340134,0.0635661855340004,0.033595625311136246,-0.01277272216975689,-0.06339843571186066,0.03142305836081505,0.04534626752138138,0.022240091115236282,-0.0021489239297807217,-0.04611313343048096,-0.07099231332540512,-0.0014782357029616833,0.006348014809191227,-0.013987936079502106,-0.029726045206189156,-0.04654031991958618,-0.042958930134773254,-0.06253252923488617,-0.055407069623470306,-0.025190947577357292,0.012607185170054436,0.046941619366407394,0.06669247150421143,0.06199969723820686,-0.0320928655564785,-0.0557071715593338,-0.05126805230975151,-0.04546220228075981,-0.03741417080163956,0.07991316169500351,0.05258236080408096,0.021326757967472076,-0.022515906020998955,0.006905759684741497,-0.0053365761414170265,-0.015365867875516415,-0.010125258006155491,0.008248732425272465,-0.02007407881319523,-0.03777993842959404,-0.06496533006429672,-0.05131100118160248,0.1246572956442833,0.06128932163119316,0.052248768508434296,-0.009484915994107723,-0.03802637755870819,-0.033532414585351944,0.008699140511453152,-0.01730387657880783,-0.015761764720082283,-0.014605746604502201,0.011100895702838898,0.03871473670005798,-0.03934793546795845,-0.03570202365517616,-0.012672116048634052],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Real 0\",\"y\":[-0.0023693388030841746,0.5429695468241843,-0.2570423720846442,-0.31461303242166155,0.21139248203157301,0.09625578092321961,-0.07551961488467931,0.21255517674276392,0.09649496811240386,0.33863875624168377,0.1395111980653739,-0.8797003337805778,0.6776130274766297,0.49622359362600166,-0.7973240925271793,-0.7446449757849122,-0.9521218413114819,0.6527047593685305,0.36190428420493576,-0.02925522523288199,1.0,1.0,-1.0,1.0,-0.17022032795852196,-0.3268192298479129,-0.39402802832309863,-1.0,-0.8646480892405678,-0.433481231902361,-0.9002025147305159,-0.5923613702581076,0.4002002937724287,-0.6032064852454305,-0.5858974306100448,-0.04245019367570544,0.7729094051928981,0.174290740136754,0.09746179036378261,0.5458108773274561,-0.4192620647868138,1.0,1.0,0.4559334305164592,-0.3939481435451069,0.9655510612385089,0.022527861921988523,-0.01508919295763634,0.40365363273052773,0.6456382791177808,1.0,1.0,-0.3771528026265061,-0.6561724608722392,-0.3912607102284789,-1.0,-0.41927855446839485,-0.25691867539343244,0.9493536406013764,-0.9271337870978927,0.7553098987323604,0.4246063526134063,-0.1656177000029629,0.39302085731312686,0.8680449146161537,0.18565823633439052,-0.1270301177566924,-0.373612385333935,0.8982875694838413,-0.733628186725022,0.9151323899445912,-0.48997032741109875,-0.7459220480430183,1.0,-1.0,-0.7692062431753419,1.0,0.5109139661876121,0.659158919065275,0.3633875506332926,-0.20248247207523343,0.5706805633222842,-1.0,-0.015886200491944898,-0.012502311660686148,0.23681629041781369,0.5164228211029174],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Predicted 1\",\"y\":[-0.0070519037544727325,-0.03439672663807869,-0.023350387811660767,-0.01564151793718338,-0.03384469449520111,-0.03732229769229889,-0.044615406543016434,-0.06172005087137222,-0.05791689455509186,-0.07503074407577515,-0.05330140143632889,-0.03993606939911842,-0.018222006037831306,0.0282160434871912,0.06250369548797607,-0.062070686370134354,-0.0823880136013031,-0.06585560739040375,-0.05673466622829437,-0.07282466441392899,-0.04242512211203575,0.16292810440063477,0.10474063456058502,0.1592870056629181,0.10544297099113464,0.028834305703639984,-0.04106245934963226,-0.08384563773870468,0.18092846870422363,0.21035534143447876,0.20005424320697784,0.15273258090019226,0.09631161391735077,0.0004815952852368355,-0.10037325322628021,0.05865168571472168,0.09625266492366791,0.05375257506966591,0.014284061267971992,-0.06139826774597168,-0.10294854640960693,0.02089107595384121,0.04889894649386406,0.014956029132008553,-0.015334229916334152,-0.04621246084570885,-0.033316873013973236,-0.12383581697940826,-0.10484857857227325,-0.0404462069272995,0.046702586114406586,0.12396162748336792,0.15922439098358154,0.14420591294765472,-0.03307719528675079,-0.08635285496711731,-0.07754597067832947,-0.06677749752998352,-0.040702272206544876,0.15701888501644135,0.11386449635028839,0.0629052221775055,-0.020659025758504868,0.007523628883063793,-0.007833351381123066,-0.021977659314870834,-0.010348372161388397,0.02142006903886795,-0.036704741418361664,-0.07059851288795471,-0.1217251867055893,-0.0914028137922287,0.2841847240924835,0.17511476576328278,0.15510854125022888,0.03385729715228081,-0.013199666514992714,-0.07041218131780624,0.01717093214392662,-0.03401239961385727,-0.030788462609052658,-0.021719876676797867,0.026003755629062653,0.0837574303150177,-0.07280578464269638,-0.06336449831724167,-0.014888730831444263],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Real 1\",\"y\":[-0.6909663353905955,0.540596954402921,0.2866727901770343,-0.5720083796627162,-0.10365258260107074,-0.12708777994943632,0.020868346188650355,0.13693185697993632,-0.01950172521727639,0.4352662329602994,0.4786149790692463,-0.7399975564570498,-0.20329532644627846,1.174767131362164,-0.3004190758379129,-0.8182973387958433,-1.6977893768193937,0.8408487560103958,1.0155053493562813,0.3331460323709797,0.9707046009715735,1.6071829709322616,0.0,0.0,0.8297796720414781,-0.4972733073878682,-0.7212960521493661,-1.394569114618714,-1.3758704995139213,-1.299316671275378,-1.334279010769256,-1.493800059090431,-0.19297451765346263,-0.20245662931270803,-1.1899322497280216,-0.632784126427851,0.7304009181563322,0.9482615182697498,0.2719918696443585,0.6434065039549595,0.1272983297437118,0.7100423505531371,2.0,1.4559334305164593,0.06261138286614254,0.5710619410969843,0.989404835048483,0.5896012384027645,0.3885437190247862,1.0498462161950715,1.6465248810842503,2.0,0.6228471973734939,-1.033843176434337,0.6087392897715211,-1.3917979963936746,-1.4192785544683948,-0.6767729906289833,0.6920821599140294,-1.9271337870978926,-0.17309704496948175,1.1809534563306152,0.25957172960475805,0.546011076696596,1.2616054751597543,1.054895165664006,0.05888306776945029,-0.5008169431073467,1.3562736881049458,0.16589292722375992,0.1804967719472217,0.4264187386054464,0.2540779519569817,0.2530536385356468,0.0,-1.769206243175342,0.22973746913249737,0.42791935595421055,0.636202261116238,1.0234516384482548,0.1614040888048219,0.36792003871558876,-0.4285357679795728,-1.015886200491945,-0.10372451241099725,0.22429681036042262,0.75356431186211],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Predicted 0\",\"y\":[0.005514420568943024,0.0027382634580135345,-0.031179405748844147,0.008188044652342796,0.007115626707673073,-0.002712290734052658,-0.005437469109892845,-0.0029288306832313538,-0.005476728081703186,0.00023354962468147278,-0.030777141451835632,-0.05033431202173233,-0.0005719717592000961,0.031616419553756714,-0.005091411992907524,0.0030039511620998383,0.000535912811756134,-0.034230127930641174,0.029423190280795097,-0.010364784859120846,0.006816431879997253,-0.05417448282241821,0.014553466811776161,0.006466573104262352,0.018986599519848824,0.031686440110206604,-0.0037379637360572815,0.04696133732795715,0.03781518340110779,0.037957027554512024,0.021632501855492592,0.038804203271865845,0.055568210780620575,0.03881008177995682,-0.03486071899533272,0.041929177939891815,0.01385350339114666,0.01808539591729641,0.03544995188713074,-0.01395194698125124,0.01358882151544094,-0.06637034565210342,-0.056076906621456146,-0.0153077132999897,0.008145717903971672,0.014476267620921135,0.015383442863821983,0.01934845931828022,0.014355672523379326,-0.030518796294927597,-0.020982224494218826,0.01136682741343975,0.037383392453193665,0.03746351599693298,0.012202812358736992,-0.06418085843324661,0.0015679467469453812,-0.004600288346409798,0.1158384308218956,0.03295951336622238,-0.07536002993583679,0.14081606268882751,0.01884257234632969,-0.04195569455623627,0.0696888417005539,0.14968658983707428,0.16379721462726593,-0.05010125786066055,0.017049388960003853,0.00629180483520031,0.009572798386216164,0.010829666629433632,-0.030951837077736855,-0.01554971281439066,0.02417050488293171,0.013563936576247215,0.020783638581633568,-0.015524329617619514,-0.015152517706155777,-0.0017728805541992188,0.12858209013938904,0.08016607910394669,0.019131338223814964,-0.009521876461803913,-0.022943001240491867,0.22749555110931396,0.049576692283153534,-0.050292499363422394,-0.0017200596630573273,0.01688709296286106,-0.04448043927550316,0.002129495143890381,0.05522332340478897,-0.019605914130806923,0.0009493175894021988,0.017879782244563103,0.037799566984176636,0.03455566614866257,0.04254383593797684,-0.01991043984889984,0.04662114381790161,-0.0036093611270189285,0.023826824501156807,0.02712954394519329,-0.02738269791007042,0.019055431708693504,-0.04363185912370682,-0.058206573128700256,-0.03648674115538597,0.03122956119477749,-0.01301889680325985,0.017531489953398705,0.014297017827630043,0.01289965771138668,-0.020693102851510048,-0.02307882159948349,-0.030909979715943336,0.03081635944545269,0.07845968008041382,0.00507853738963604,0.009175537154078484,0.01810588873922825,0.0005342531949281693,0.03800494223833084,-0.00595763698220253,-0.015373973175883293,0.14257226884365082,0.005675852298736572,-0.03403134271502495,-0.038974158465862274,-0.0354616716504097,0.025623062625527382,0.04244425892829895,0.08407603949308395,0.07130957394838333,0.04607955366373062,0.24126702547073364,0.18199099600315094,-0.011066801846027374,0.0029866360127925873,-0.020486634224653244,0.05686970800161362,-0.023153135553002357,0.04484383016824722,0.055445343255996704,-0.005617406219244003,0.039506152272224426,0.034217819571495056,0.021813133731484413,0.054054297506809235,0.001361733302474022,-0.0012126658111810684,0.025292227044701576,0.027398599311709404,0.020287996158003807,-0.033140379935503006,-0.00746532529592514,-0.06286469101905823,-0.01107005961239338,-0.014061074703931808,0.023428549990057945,0.019606543704867363,0.018063073977828026,0.01582401804625988,0.011720674112439156,0.05519004166126251,0.0290296021848917,0.013270648196339607,0.014003252610564232,0.032928064465522766,-0.025946151465177536,-0.010039398446679115,0.03423544019460678,-0.04224548488855362,-0.02049138955771923,0.04116258770227432,0.030847808346152306,0.07364518195390701,0.02085673250257969,0.0017143767327070236,-0.04398547112941742,0.025362705811858177,0.003672465682029724,0.0833522230386734,0.034247808158397675,0.2234269678592682,0.1528179794549942,-0.04296325892210007,-0.07168257236480713,-0.00416259840130806,-0.02166750282049179,0.04276462644338608,0.01932167448103428,0.015880094841122627,-0.0055731795728206635,-0.010744997300207615,0.03988363593816757,0.0006019268184900284,0.09291499853134155,0.006261361762881279,0.0005230177193880081],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Real 0\",\"y\":[0.159741736610641,0.2671208721207905,0.037003388223405445,0.7417216274125243,0.606645906148696,0.014005212424922414,-0.16948762777622145,0.4627359925221703,-0.6842714728115343,-0.9615489533526314,-0.6194707221516623,0.6103329217981122,0.14880353023027992,0.7574728636854214,0.3032239584896389,0.597482924667757,0.5101800794793434,-1.0,-1.0,-0.15917909322245763,0.5550475832815532,0.1649949797843552,0.5828473820689877,-0.13365130584872648,0.10608373620113794,0.4759591923349177,-0.20318816821686803,-0.3836093368712614,0.19808775906523038,-0.08358501171969025,-0.16879393258087438,0.1622733820383905,0.1314099133631723,-0.6310357627963155,-0.2174218267087505,0.894332519120347,0.27523513012068307,1.0,0.5490481289724141,-0.030168949703636223,0.5355164523058462,-0.9048675656098922,0.9718278240598652,-0.14368467419498804,0.4651988909512069,-0.07614238831691059,0.5640067389816492,0.10408959037407343,-0.11875223652378332,0.6759041818037934,1.0,0.8127695215706155,1.0,-0.223959959361155,-0.08438579304348226,0.372414558019872,-0.07214940671525547,-0.007841328811076832,-1.0,-0.6466783787567043,-0.6010650409003571,1.0,-0.7489061514774111,-1.0,1.0,0.057177445994469465,-0.6349582421909656,1.0,0.3118487062520686,0.48456617128198176,0.4775323965668563,0.40589216105344483,-0.49958951378464944,-1.0,-0.7878379255080901,-0.29073861529042394,0.5289401011745231,-0.17829031320325064,-0.629534346892541,0.30056128626996503,0.7049089052445899,-1.0,-0.35809314001673975,0.5835039601169881,-0.5697460298490044,-0.41589211615657523,-0.9201666156510124,-1.0,0.8276983425398008,0.45471028080326337,-0.6182827487405491,0.5901599210635969,-0.45540175583928094,0.18280575393562698,0.8238789868295666,0.45647926254391175,0.7837244932195117,-0.2437225433243221,-0.33825846868905773,0.2554031285432298,0.9281422187670333,-0.06079032238502096,-0.012380079345811689,0.9414730834215026,0.13549316203610184,0.721659140903111,-0.8054282904846104,0.7703185769484182,-1.0,0.4237983534867972,0.2488569192315371,0.6382118182478118,0.2631742384717633,0.5025091582920623,-0.11753771243436814,1.0,0.9155374157905527,1.0,0.26795032970511284,-0.6680686262988698,-0.2587382363289026,0.3632921130523922,0.5743385380787959,0.5872442955808741,-0.7557126136360556,-0.26661768937384456,1.0,-0.8783797353728138,-1.0,0.22708317877488074,1.0,-0.9519423399262489,0.5381376818140241,1.0,-0.09998939181121833,-0.9638583327611805,0.11145172165541309,-1.0,-1.0,-0.7424181399533545,0.0027199905597975944,-0.6239120808556371,-0.3318233749344049,1.0,0.07425591345193344,-1.0,-1.0,-0.17015979202525677,0.10242525361735816,-0.10547891693646966,-0.5272513084242711,-0.6440872370945279,0.6205798434004792,0.2260861425996579,0.3404122441194398,0.06977491667467701,0.41898783968889486,0.060491644371006174,1.0,0.7395204445264745,0.6587295522834389,0.9343781888029504,-0.0751718490385134,-0.04810662339070041,-0.09397925819983402,-0.21285327663723203,0.2066328284054403,0.41397195900622935,-0.5625817733412467,0.1549631866858353,-0.45249415861203185,1.0,1.0,0.44216020395411265,1.0,-0.9577690912960994,0.0387856985611972,0.06892060562581921,-1.0,-0.21898556365601227,-1.0,-1.0,1.0,0.3812667888864722,-1.0,0.21124692952468374,-1.0,0.2296797923216649,0.2949595303801359,0.8239060013230082,-0.4238216991796907,0.4172349500718179,0.7738854692085909,-0.7191930115606201,-0.09540146398301066,0.5632009419611165,1.0,0.008783142983852792,0.4333025014343442,-0.32720585224787285,-1.0],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Predicted 1\",\"y\":[0.013362491503357887,0.015740467235445976,-0.0325823649764061,0.023053500801324844,0.02447725459933281,0.007545849308371544,-0.0007497482001781464,0.019961318001151085,0.0006333384662866592,0.011548461392521858,-0.044646453112363815,-0.059729404747486115,0.011919546872377396,0.07303405553102493,0.025675691664218903,0.0309563260525465,0.030174272134900093,0.03037949651479721,0.07114791125059128,0.017343107610940933,0.023488139733672142,-0.03482078015804291,0.03886869549751282,0.016439370810985565,0.036813538521528244,0.06155427545309067,0.008644511923193932,0.0956597700715065,0.08332369476556778,0.08007439225912094,0.05691870301961899,0.07928498089313507,0.10803502798080444,0.08888746798038483,-0.005666924640536308,0.06992875784635544,0.03540492057800293,0.05735349655151367,0.08017410337924957,0.009152987040579319,0.05161522328853607,-0.08106803148984909,-0.03870244324207306,-0.0232599638402462,0.02184901013970375,0.03307648375630379,0.03538186848163605,0.045313239097595215,0.038842566311359406,0.0036191754043102264,-0.0005365107208490372,0.05221258103847504,0.07854408025741577,0.0822896659374237,0.05010680854320526,-0.05251334607601166,0.012803412973880768,0.00022125430405139923,0.15585772693157196,0.0781785100698471,-0.06257305294275284,0.1564093381166458,0.03569129854440689,-0.05386582762002945,0.1305818110704422,0.20767585933208466,0.19496040046215057,-0.022414403036236763,0.0510890856385231,0.03929217904806137,0.04143489897251129,0.042870618402957916,-0.030833395197987556,0.046151258051395416,0.06935384124517441,0.0482354536652565,0.05042625591158867,0.0014536380767822266,-0.019034486263990402,0.001200202852487564,0.16278111934661865,0.08462806791067123,0.045261699706315994,-0.004871672950685024,-0.042830921709537506,0.26000675559043884,0.10150792449712753,-0.025955351069569588,0.025003893300890923,0.05110381543636322,-0.05007515475153923,0.0194369088858366,0.09793676435947418,-0.015913372859358788,0.01030656322836876,0.057701192796230316,0.08684810996055603,0.07636179774999619,0.09581013023853302,0.021081313490867615,0.08923286944627762,0.040323227643966675,0.05374366044998169,0.06980191916227341,-0.00503922812640667,0.05943933129310608,-0.04447674751281738,-0.034649111330509186,-0.04474686086177826,0.06828656792640686,0.013129685074090958,0.045516353100538254,0.03307901322841644,0.04035266488790512,-0.027652421966195107,0.017516866326332092,0.020322909578680992,0.07512594759464264,0.11860605329275131,0.02590683475136757,0.01788545399904251,0.042826056480407715,0.03463682532310486,0.07048143446445465,-0.0016508400440216064,-0.01777937076985836,0.17121203243732452,0.028729571029543877,-0.043180596083402634,-0.01239624060690403,0.037390708923339844,0.07140375673770905,0.08847963064908981,0.14704065024852753,0.13757506012916565,0.06689906865358353,0.3029606342315674,0.2296275496482849,0.01872575469315052,0.01984218694269657,-0.014344053342938423,0.11885067075490952,0.0333888903260231,0.09614292532205582,0.07493405789136887,-0.012089261785149574,0.08946504443883896,0.07264479994773865,0.05931495130062103,0.11343465745449066,0.052105627954006195,0.025471307337284088,0.05905134230852127,0.0551736019551754,0.05469531565904617,-0.016827335581183434,0.015478136017918587,-0.06270693242549896,0.021188220009207726,0.016722416505217552,0.05642648786306381,0.049583565443754196,0.0446220263838768,0.04278089478611946,0.02978069707751274,0.1148974820971489,0.07747157663106918,0.06210421770811081,0.04488278925418854,0.04020591080188751,-0.025631150230765343,0.013753790408372879,0.09051153063774109,-0.002507627010345459,0.05342777073383331,0.08789976686239243,0.06567081063985825,0.10690666735172272,0.04435965046286583,0.013578850775957108,0.007557213306427002,0.058720581233501434,0.03906567394733429,0.1703619360923767,0.08112496882677078,0.23676662147045135,0.15391801297664642,-0.04471705108880997,-0.09550933539867401,0.0006995406001806259,-0.04464810714125633,0.09923306852579117,0.06792513281106949,0.04005841165781021,0.013590006157755852,0.03020799160003662,0.08575566112995148,0.031189408153295517,0.14828956127166748,0.067019984126091,0.02016713097691536],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Real 1\",\"y\":[-0.16511796488336072,0.30710070530770855,0.30412426034419593,1.0593321971499583,1.3483675335612202,0.6206511185736183,-0.15548241535129903,0.6497826845604995,-0.22153548028936404,0.03845104664736865,-1.5810196755042938,-0.009137800353550163,-0.3169850636119728,0.9062763939157014,1.0606968221750603,0.9007068831573959,1.1076630041471005,-2.0,-2.0,-1.1591790932224577,0.39586849005909563,0.7200425630659084,0.8446150972391178,0.4491960762202612,0.15260447738978553,0.5820429285360557,-0.07902538639644638,0.21676889332837856,-0.18552157780603104,0.11450274734554013,-0.2523789443005646,0.2091438996534045,0.2936832954015628,-0.49962584943314314,-0.8484575895050659,0.6769106924115964,0.0364856371740421,0.1627427593398163,1.549048128972414,0.5188791792687778,0.50534750260221,-0.369351113304046,0.066960258449973,-0.5363106358368268,0.3215142167562189,-0.41435719592688125,0.48786435066473866,0.6680963293557226,-0.014662646149709885,1.6759041818037934,1.6759041818037934,1.8127695215706154,1.0244569300312518,0.776040040638845,-0.30834575240463724,0.28802876497638974,0.058284179234437516,-0.07999073552633229,-2.0,-1.6466783787567043,-1.2477434196570614,0.39893495909964294,0.25109384852258887,-1.7489061514774111,0.08079670602445799,1.0571774459944694,-0.5777807961964961,1.593822285293645,0.20733645905516465,0.7964148775340504,0.9620985678488381,0.8834245576203011,-0.09369735273120461,-2.0,-1.78783792550809,-1.078576540798514,0.23820148588409912,0.35064978797127244,-0.8078246600957916,-0.3289730606225759,-0.29509109475541007,-0.29509109475541007,-1.3580931400167398,0.5311474795647286,0.013757930267983776,0.5841078838434248,-0.925306999423804,-1.9201666156510124,-0.1723016574601992,1.282408623343064,-0.16357246793728575,-0.028122827676952178,0.41908357254477474,0.5666043232678302,1.0066847407651935,0.2712825645389061,1.2402037557634233,0.5400019498951896,-0.8405577831215526,-0.08285534014582796,1.183545347310263,0.8673518963820124,0.29188391549552894,1.9233649502261623,1.0769662454576046,0.8571523029392129,-0.08376914958149939,-0.03510971353619219,-0.2296814230515818,0.9986696762454855,0.6726552727183343,0.16214939273178053,0.9013860567195751,0.7656833967638257,0.38497144585769416,1.5159663623111173,1.9155374157905527,1.9155374157905527,1.267950329705113,-0.4001182965937569,-0.4134330443688826,0.10455387672348959,0.11116423023815947,1.1615828336596699,-0.16846831805518148,-1.0223303030099,0.25416518951002964,0.12162026462718623,-1.8783797353728138,-0.17994643371637845,1.2270831787748808,0.04805766007375112,-0.4138046581122248,1.4369805647295049,0.9000106081887816,-1.0638477245723987,1.1114517216554132,-0.8885482783445869,-2.0,-1.7424181399533545,-0.7396981493935569,-1.623912080855637,-0.9557354557900419,0.6681766250655952,0.6779241750607938,-0.9257440865480666,-1.027938420136721,-1.1701597920252569,-0.06773453840789861,0.37375464341378833,-0.6327302253607408,-1.171338545518799,-0.02350739369404864,-0.1409440511623475,0.5664983867190977,0.4101871607941168,-0.4215703512388155,-0.025442974778818093,1.0604916443710062,1.7395204445264745,1.3982499968099134,0.3822058522841748,0.859206339764437,-0.1232784724292138,-0.14208588159053442,-0.8923467625986785,-0.006220448231791714,0.6206047874116697,-0.14860981433501735,-0.4076185866554114,-0.29753097192619654,1.0125773238182096,2.0,1.4421602039541126,1.4421602039541126,0.04223090870390056,-0.9189833927349023,0.1077063041870164,-0.9310793943741807,-1.2189855636560123,-2.0,-2.0,1.2057869113396402,1.3812667888864723,-0.6187332111135277,-0.7887530704753163,-0.7887530704753163,1.0368560876551114,0.5246393227018008,1.1188655317031442,0.40008430214331747,1.3565570297568104,0.4509039018820056,0.054692457647970816,-0.8145944755436307,0.18223903340035041,1.5632009419611164,1.0087831429838527,1.0372852198180267,0.10609664918647133,-1.327205852247873],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3f7cfd85-12df-4bfc-a95e-d621a07756e2');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "bench_fig = visualize_future_distribution(results_benchmark)\n",
    "tuned_fig = visualize_future_distribution(results_tuned)\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "for trace in bench_fig.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in tuned_fig.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Number:\n",
      "Accuracy1D 47.13% PredictedRet: -0.004913469310849905 ActRet: 0.04711557244860369\n",
      "Accuracy2D 37.93% PredictedRet: 0.008820226415991783 ActRet: 0.10982128947322142\n",
      "Train set length: 314 Test set length: 87\n",
      "\n",
      "Cluster Number:\n",
      "Accuracy1D 55.22% PredictedRet: 0.015846332535147667 ActRet: 0.058342034458805876\n",
      "Accuracy2D 61.19% PredictedRet: 0.043984852731227875 ActRet: 0.11842633418828696\n",
      "Accuracy3D 59.2% PredictedRet: 0.07841123640537262 ActRet: 0.17888408636918932\n",
      "Accuracy4D 57.21% PredictedRet: 0.11634019762277603 ActRet: 0.21772292785495792\n",
      "Accuracy5D 60.2% PredictedRet: 0.15619394183158875 ActRet: 0.23187393435485146\n",
      "Accuracy6D 61.19% PredictedRet: 0.19761110842227936 ActRet: 0.27124266650794554\n",
      "Train set length: 707 Test set length: 201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(benchmarkAccuracy)\n",
    "# print(val_loss_benchmark)\n",
    "print(fineTunedAccuracy)\n",
    "# print(val_loss_tuned)\n",
    "# write results_tuned dataframe to csv\n",
    "results_tuned.to_csv('results_tuned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
